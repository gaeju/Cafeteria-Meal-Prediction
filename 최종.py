# -*- coding: utf-8 -*-
"""최종.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BZiV07Rm7FokR_oWYoVdEdWUwilea8WS

# 라이브러리 로드
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import re
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import mean_absolute_error

import requests
import json
from datetime import datetime
import calendar
from dateutil.relativedelta import relativedelta

# Commented out IPython magic to ensure Python compatibility.
!pip install koreanize_matplotlib
import koreanize_matplotlib

# 그래프에 retina display 적용
# %config InlineBackend.figure_format = 'retina'

"""# 데이터 로드"""



from google.colab import drive
drive.mount('/content/drive')

train_raw = pd.read_csv("/content/drive/MyDrive/AI school/구내식당/data/train.csv")
test_raw = pd.read_csv("/content/drive/MyDrive/AI school/구내식당/data/test.csv")
submission = pd.read_csv("/content/drive/MyDrive/AI school/구내식당/data/sample_submission.csv")

train = train_raw.copy()
test = test_raw.copy()
train.shape, test.shape, submission.shape

# train_raw = pd.read_csv('train.csv').copy()
# test_raw = pd.read_csv('test.csv').copy()
# submission = pd.read_csv('sample_submission.csv')

# train_raw.shape, test_raw.shape, submission.shape

train_raw.head()

test_raw.head()

train_raw.hist(bins=30, figsize=(8,8));

test_raw.hist(bins=30, figsize=(8,8));

train = train_raw.copy()
test = test_raw.copy()
train.shape, test.shape

"""# 전처리

## 데이터 타입 변경
"""

# 일자, 현본사소속재택근무자수, 중식계, 석식계 데이터 타입 변경

# train
train["일자"] = pd.to_datetime(train["일자"])
train["현본사소속재택근무자수"] = train["현본사소속재택근무자수"].astype("int")
train["중식계"] = train["중식계"].astype("int")
train["석식계"] = train["석식계"].astype("int")
train.info()

# test
test["일자"] = pd.to_datetime(test["일자"])
test["현본사소속재택근무자수"] = test["현본사소속재택근무자수"].astype("int")
test.info()

"""## 파생변수 만들기
강수량, 연도, 월, 일, 출근인원, 중식_신메뉴, 석식_신메뉴, 공휴일, 조리법, 식재료

### 강수량
"""

# train 강수량
weather = pd.read_csv("raining_train.csv",encoding='cp949')
del weather['지점']
del weather['지점명']
weather['일시'] = weather['일시'].astype('datetime64')
a = pd.merge(train,weather,how='left',left_on='일자',right_on='일시')
a = a.drop('일시',axis=1)
a['일강수량(mm)'] = a['일강수량(mm)'].fillna(0)
train = a.copy()
train.head()

# test 강수량
weather2 = pd.read_csv("raining_test.csv",encoding='cp949')
del weather2['지점']
del weather2['지점명']
weather2['일시'] = weather2['일시'].astype('datetime64')
a = pd.merge(test,weather2,how='left',left_on='일자',right_on='일시')
a = a.drop('일시',axis=1)
a['일강수량(mm)'] = a['일강수량(mm)'].fillna(0)
test = a.copy()
test.head()

"""### 연도, 월, 일, 요일"""

# train
train["연도"] = train["일자"].dt.year
train["월"] = train["일자"].dt.month
train["일"] = train["일자"].dt.day
train["요일"] = train['일자'].dt.weekday + 1

train.head(2)

# test
test["연도"] = test["일자"].dt.year
test["월"] = test["일자"].dt.month
test["일"] = test["일자"].dt.day
test["요일"] = test['일자'].dt.weekday + 1

test.head(2)

"""### 출근인원"""

# 회사에 출근한 사람 : 본사정원수 - (본사휴가자수 + 본사출장자수 + 현본사소속재택근무자수)
train["출근인원"] = train["본사정원수"] - (train["본사휴가자수"] + train["본사출장자수"] + train["현본사소속재택근무자수"])
train["중식비율"] = train["중식계"] / train["출근인원"]
train["석식비율"] = train["석식계"] / train["출근인원"]
train.head(2)

# 회사에 출근한 사람 : 본사정원수 - (본사휴가자수 + 본사출장자수 + 현본사소속재택근무자수)
test["출근인원"] = test["본사정원수"] - (test["본사휴가자수"] + test["본사출장자수"] + test["현본사소속재택근무자수"])
test.head(2)

"""### 신메뉴 여부"""

# 중식메뉴, 석식메뉴에 'New'가 포함되어 있으면 1, 없으면 0으로 이루어진 '신메뉴' 컬럼 생성
train['중식_신메뉴'] = (train['중식메뉴'].str.contains('New')).astype(int)
train['석식_신메뉴'] = (train['석식메뉴'].str.contains('New')).astype(int)
train.head(1)

# test
test['중식_신메뉴'] = (test['중식메뉴'].str.contains('New')).astype(int)
test['석식_신메뉴'] = (test['석식메뉴'].str.contains('New')).astype(int)
test.head(1)

"""### 공휴일 전날 여부"""

# 공휴일

# url = "http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo"

# AUTH_KEY = "###################################"


# params = {
#     'solYear':str(2020),
#     'solMonth':str(1).zfill(2),
#     '_type':'json',
#     'ServiceKey' : AUTH_KEY
# }

# response =  requests.get(url,params=params)
# print(response.text)

# result = json.loads(response.text)

# def getHolidays(year,month,key):
#     url = 'http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo'
#     AUTH_KEY = "###################################"

#     params = {
#         'solYear':str(year),
#         'solMonth':str(month).zfill(2),
#         '_type':'json',
#         'ServiceKey' : AUTH_KEY
#     }

#     res = requests.get(url,params=params)
#     dic = json.loads(res.text)
#     counts = dic['response']['body']['totalCount']

#     if counts < 1 :
#         return []

#     item =  dic['response']['body']['items']['item']

#     if counts == 1:
#         return [item]

#     return item

# holidays =[]
# AUTH_KEY = "###################################"
# for year in range(2016,2022):
#     for month in range(1,13):
#         holidays.extend(getHolidays(year,month,AUTH_KEY))

# df_holiday = pd.DataFrame(holidays,columns=['locdate','dateName'])
# df_holiday.columns = ["일자", "공휴일"]
# df_holiday.to_csv('./holiday.csv',index=None)
# pd.read_csv("./holiday.csv")

# 휴일 전날
#holi = pd.read_csv("/content/drive/MyDrive/AI school/235743_구내식당 식사 인원 예측 AI 경진대회_data/holiday.csv")
holi = pd.read_csv("holiday.csv")
holi["일자"] = holi["일자"].astype(str)
holiday_before_df = holi.copy()
holiday_before_df['일자'] = holiday_before_df['일자'].apply(lambda x : datetime.strptime(x,'%Y%m%d'))
holiday_before_df['일자'] = holiday_before_df['일자'].apply(lambda x : x - relativedelta(days=1))
holiday_before_df['일자'] = holiday_before_df['일자'].apply(lambda x : datetime.strftime(x, '%Y-%m-%d'))
holiday_before_df['공휴일'] = holi['공휴일'].apply(lambda x : 1)
holiday_before_df.columns = ['일자', '휴일전날']

holiday_before_df.info()

holiday_before_df.head(2)

# 휴일전날 merge
train["일자"] = train["일자"].astype(str)
train = pd.merge(train, holiday_before_df, left_on='일자', right_on='일자', how='left')
before_friday = train[train['요일']==5].index
train['휴일전날'][before_friday] = 1

train.head(2)

# 평일은 0 처리
train['휴일전날'] = train['휴일전날'].fillna(0)

train['휴일전날'].isnull().sum()

train[train['휴일전날'] == 1].head(2)

# 휴일전날 merge
test["일자"] = test["일자"].astype(str)
test = pd.merge(test, holiday_before_df, left_on='일자', right_on='일자', how='left')
before_friday = test[test['요일']==5].index
test['휴일전날'][before_friday] = 1

test.head(2)

# 평일은 0 처리
test['휴일전날'] = test['휴일전날'].fillna(0)

test['휴일전날'].isnull().sum()

test[test['휴일전날'] == 1].head(2)

"""### 조리법"""

# 조리법

train['중식메뉴_1'] = train['중식메뉴'].str.split(' ')
train['석식메뉴_1'] = train['석식메뉴'].str.split(' ')

test['중식메뉴_1'] = test['중식메뉴'].str.split(' ')
test['석식메뉴_1'] = test['석식메뉴'].str.split(' ')

def get_token(data) :
    tokens = []
    for token in data :#하루의 중식 메뉴
        s_list = []
        for t in token : #중식 메뉴 중 밥, 국,...
            if t.startswith('(') :
                s_list.append(t)
            elif (t.startswith('(') == False) & (len(t) > 1) :
                s_list.append(t)
            else :
                pass
        tokens.append(s_list)
    return tokens

train['중식_토큰'] = get_token(train['중식메뉴_1'])
train['석식_토큰'] = get_token(train['석식메뉴_1'])

test['중식_토큰'] = get_token(test['중식메뉴_1'])
test['석식_토큰'] = get_token(test['석식메뉴_1'])

def get_ingredient(data) :

    ing_df = pd.DataFrame(np.zeros((data.shape[0], 7)), columns = ['해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타'])

    for t in range(data.shape[0]):
        token = data.중식_토큰.str[2][t]
        if '연어' in token or'골뱅이' in token or'열기' in token or'조기' in token or'탕수어' in token or'양장피' in token or'홍어' in token or'명태' in token or'적어' in token or'장어' in token or'동태' in token or'산슬' in token or'코다리' in token or'가자미' in token or'해물' in token or'생선' in token or'새우' in token or'꽁치' in token or'갈치' in token or'임연수' in token or'삼치' in token or'고등어' in token or'굴비' in token or'오징어' in token or'쭈꾸미' in token or'주꾸미' in token or'낙지' in token or'문어' in token :
            ing_df.head().at[t, '해산물'] = 1
        elif '왕갈비' in token or'소갈비' in token or'장조림' in token or'불고기' in token or'차돌' in token or'육전' in token or'너비아니' in token or'떡갈비' in token or(token.startswith('소') & (token.startswith('소세') == False)) or '함박' in token or'쇠고기' in token or'소고기' in token or'쇠' in token :
            ing_df.at[t, '소'] = 1
        elif '궁보계정' in token or'삼계탕' in token or'윙' in token or'유린기' in token or'깐풍'in token or'닭' in token or'치킨' in token or'후라이드' in token :
            ing_df.at[t, '돼지'] = 1
        elif '폭립' in token or'오향장육' in token or'동파육' in token or'히레카츠' in token or'순대' in token or'미트볼' in token or'등갈비' in token or'소세지' in token or'목살' in token or'탕수육' in token or'제육' in token or'돈' in token or'돼지' in token or'두루치기' in token or'삼겹' in token or'보쌈' in token or'족발' in token :
            ing_df.at[t, '닭'] = 1
        elif '오리' in token :
            ing_df.at[t, '오리'] = 1
        elif token.endswith('두부') or '꼬치산적' in token or '고추' in token or'양파' in token or'부추' in token or'고구마' in token or'감자' in token or'깻잎' in token or'샐러드' in token or'시금치' in token or'야채' in token :
            ing_df.at[t, '채소'] = 1
        else :
            ing_df.at[t, '재료_기타'] = 1
            pass
    return ing_df

train = pd.concat([train, get_ingredient(train)], axis = 1)
test = pd.concat([test, get_ingredient(test)], axis = 1)

train['중식_메인요리'] = train.중식_토큰.str[3]
test['중식_메인요리'] = test.중식_토큰.str[2]

train['석식_메인요리'] = 0
if train.shape[0] < 1067:
    train['석식_메인요리'] = train.석식_토큰.str[3]
else:
    train['석식_메인요리'] = train.석식_토큰.str[2]
test['석식_메인요리'] = test.석식_토큰.str[2]

#조리법 종류 별 컬럼 생성 함수
def get_recipe(data, col) :
    tm = col[:2]
    cat = ['전', '무침','튀김', '찜', '볶음', '조림', '구이', '훈제', '조리_기타']
    recipe_df = pd.DataFrame(np.zeros((data.shape[0], 9)), columns = [f'{tm}_{x}' for x in cat])

    for t in range(data.shape[0]) :
        try :
            token = data[col][t]
            if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :
                recipe_df.at[t, f'{tm}_볶음'] = 1
            elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :
                recipe_df.at[t, f'{tm}_구이'] = 1
            elif '전병' in token or token.endswith('전') :
                recipe_df.at[t, f'{tm}_전'] = 1
            elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :
                recipe_df.at[t, f'{tm}_찜'] = 1
            elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :
                recipe_df.at[t, f'{tm}_무침'] = 1
            elif '오향장육' in token or '동파육' in token or token.endswith('조림') :
                recipe_df.at[t, f'{tm}_조림'] = 1
            elif '튀김' in token or '통닭' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :
                recipe_df.at[t, f'{tm}_튀김'] = 1
            elif '훈제' in token :
                recipe_df.at[t, f'{tm}_훈제'] = 1
            else :
                recipe_df.at[t, f'{tm}_조리_기타'] = 1
        except :
            recipe_df.at[t, f'{tm}_조리_기타'] = 1
    return recipe_df

train = pd.concat([train, get_recipe(train, '중식_메인요리')], axis = 1)
train = pd.concat([train, get_recipe(train, '석식_메인요리')], axis = 1)

train['중식메인조리법'] = 0
for t in range(train.shape[0]) :
    token = train['중식_메인요리'][t]
    if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :
        train.loc[t, '중식메인조리법'] = 1
    elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :
        train.loc[t, '중식메인조리법'] = 2
    elif '전병' in token or token.endswith('전') :
        train.loc[t, '중식메인조리법'] = 3
    elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :
        train.loc[t, '중식메인조리법'] = 4
    elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :
        train.loc[t, '중식메인조리법'] = 5
    elif '오향장육' in token or '동파육' in token or token.endswith('조림') :
        train.loc[t, '중식메인조리법'] = 6
    elif '통닭' in token or '튀김' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :
        train.loc[t, '중식메인조리법'] = 7
    elif '훈제' in token :
        train.loc[t, '중식메인조리법'] = 8
    else :
        train.loc[t, '중식메인조리법'] = 9

train['석식메인조리법'] = 0
for t in range(train.shape[0]) :
    token = str(train['석식_메인요리'][t])
    if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :
        train.loc[t, '석식메인조리법'] = 1
    elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :
        train.loc[t, '석식메인조리법'] = 2
    elif '전병' in token or token.endswith('전') :
        train.loc[t, '석식메인조리법'] = 3
    elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :
        train.loc[t, '석식메인조리법'] = 4
    elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :
        train.loc[t, '석식메인조리법'] = 5
    elif '오향장육' in token or '동파육' in token or token.endswith('조림') :
        train.loc[t, '석식메인조리법'] = 6
    elif '통닭' in token or '튀김' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :
        train.loc[t, '석식메인조리법'] = 7
    elif '훈제' in token :
        train.loc[t, '석식메인조리법'] = 8
    else :
        train.loc[t, '석식메인조리법'] = 9

test = pd.concat([test, get_recipe(test, '중식_메인요리')], axis = 1)

test = pd.concat([test, get_recipe(test, '석식_메인요리')], axis = 1)

test['중식메인조리법'] = 0
for t in range(test.shape[0]) :
    token = test['중식_메인요리'][t]
    if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :
        test.loc[t, '중식메인조리법'] = 1
    elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :
        test.loc[t, '중식메인조리법'] = 2
    elif '전병' in token or token.endswith('전') :
        test.loc[t, '중식메인조리법'] = 3
    elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :
        test.loc[t, '중식메인조리법'] = 4
    elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :
        test.loc[t, '중식메인조리법'] = 5
    elif '오향장육' in token or '동파육' in token or token.endswith('조림') :
        test.loc[t, '중식메인조리법'] = 6
    elif '통닭' in token or '튀김' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :
        test.loc[t, '중식메인조리법'] = 7
    elif '훈제' in token :
        test.loc[t, '중식메인조리법'] = 8
    else :
        test.loc[t, '중식메인조리법'] = 9

test['석식메인조리법'] = 0
for t in range(test.shape[0]) :
    token = str(test['석식_메인요리'][t])
    if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :
          test.loc[t, '석식메인조리법'] = 1
    elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :
        test.loc[t, '석식메인조리법'] = 2
    elif '전병' in token or token.endswith('전') :
        test.loc[t, '석식메인조리법'] = 3
    elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :
        test.loc[t, '석식메인조리법'] = 4
    elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :
        test.loc[t, '석식메인조리법'] = 5
    elif '오향장육' in token or '동파육' in token or token.endswith('조림') :
        test.loc[t, '석식메인조리법'] = 6
    elif '통닭' in token or '튀김' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :
        test.loc[t, '석식메인조리법'] = 7
    elif '훈제' in token :
        test.loc[t, '석식메인조리법'] = 8
    else :
        test.loc[t, '석식메인조리법'] = 9

train = train.drop(columns = ['중식메뉴_1', '석식메뉴_1',
       '중식_토큰', '석식_토큰', '해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타', '중식_메인요리',
       '석식_메인요리'], axis = 1)
train.columns

test = test.drop(columns = ['중식메뉴_1',
       '석식메뉴_1', '중식_토큰', '석식_토큰', '해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타',
       '중식_메인요리', '석식_메인요리'], axis = 1)
test.columns

train.head()

train.head()

"""### 식재료"""

# train ln
lunch = []
for day in range(len(train)):
    tmp = train.iloc[day, 8].split(' ') # 공백으로 문자열 구분
    tmp = ' '.join(tmp).split()    # 빈 원소 삭제

    search = '('   # 원산지 정보 삭제
    for menu in tmp:
        if search in menu:
            tmp.remove(menu)

    lunch.append(tmp)

bob = []; gook = []; banchan1 = []; banchan2 = []; banchan3 = []; kimchi = []; side = []

for i, day_menu in enumerate(lunch):
    bob_tmp = day_menu[0]; bob.append(bob_tmp)
    gook_tmp = day_menu[1]; gook.append(gook_tmp)
    banchan1_tmp = day_menu[2]; banchan1.append(banchan1_tmp)
    banchan2_tmp = day_menu[3]; banchan2.append(banchan2_tmp)
    banchan3_tmp = day_menu[4]; banchan3.append(banchan3_tmp)

    if i < 1067:
        kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)
        side_tmp = day_menu[-2]; side.append(side_tmp)
    else:
        kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)
        side_tmp  = day_menu[-1]; side.append(side_tmp)

train_ln = train.copy()
train_ln['bob'] = bob
train_ln['gook'] = gook
train_ln['banchan1'] = banchan1
train_ln['banchan2'] = banchan2
train_ln['banchan3'] = banchan3
train_ln['kimchi'] = kimchi
train_ln['side'] = side
train_ln.iloc[1066:1070, 7:]
# train_ln.info()

# test ln
lunch = []
for day in range(len(test)):
    tmp = test.iloc[day, 8].split(' ') # 공백으로 문자열 구분
    tmp = ' '.join(tmp).split()    # 빈 원소 삭제

    search = '('   # 원산지 정보 삭제
    for menu in tmp:
        if search in menu:
            tmp.remove(menu)

    lunch.append(tmp)

bob = []; gook = []; banchan1 = []; banchan2 = []; banchan3 = []; kimchi = []; side = []

for i, day_menu in enumerate(lunch):
    bob_tmp = day_menu[0]; bob.append(bob_tmp)
    gook_tmp = day_menu[1]; gook.append(gook_tmp)
    banchan1_tmp = day_menu[2]; banchan1.append(banchan1_tmp)
    banchan2_tmp = day_menu[3]; banchan2.append(banchan2_tmp)
    banchan3_tmp = day_menu[4]; banchan3.append(banchan3_tmp)

    if i < 1067:
        kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)
        side_tmp = day_menu[-2]; side.append(side_tmp)
    else:
        kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)
        side_tmp  = day_menu[-1]; side.append(side_tmp)

test_ln = test.copy()
test_ln['bob'] = bob
test_ln['gook'] = gook
test_ln['banchan1'] = banchan1
test_ln['banchan2'] = banchan2
test_ln['banchan3'] = banchan3
test_ln['kimchi'] = kimchi
test_ln['side'] = side
# test_ln.iloc[1066:1070, 7:]
test_ln.head()

# train_ln = train_ln[['year','month','day','dow','employees', 'dayoff', 'bustrip', 'ovtime', 'remote','real_emp','bob','gook','banchan1','banchan2','banchan3', 'kimchi','side','target_ln']]
# test_ln = test_ln[['year','month','day','dow','employees', 'dayoff', 'bustrip', 'ovtime', 'remote','real_emp','bob','gook','banchan1','banchan2','banchan3', 'kimchi','side']]

test_ln

# train_dn
dinner = []
for day in range(len(train)):
    tmp = train.iloc[day, 9].split(' ') # 공백으로 문자열 구분
    tmp = ' '.join(tmp).split()    # 빈 원소 삭제

    search = '('   # 원산지 정보 삭제
    for menu in tmp:
        if search in menu:
            tmp.remove(menu)

    dinner.append(tmp)

dinner

bob = []; gook = []; banchan1 = []; banchan2 = []; banchan3 = []; kimchi = []; side = []
for i, day_menu in enumerate(dinner):
    if (len(day_menu) < 4 ):
        bob.append('*')
        gook.append('*')
        banchan1.append('*')
        banchan2.append('*')
        banchan3.append('*')

        if i < 1067:
            kimchi.append('*')
            side.append('*')
        else:
            kimchi.append('*')
            side.append('*')

    elif (len(day_menu)==4):
        bob_tmp = day_menu[0]; bob.append(bob_tmp)
        gook_tmp = day_menu[1]; gook.append(gook_tmp)
        banchan1_tmp = day_menu[2]; banchan1.append(banchan1_tmp)
        banchan2_tmp = day_menu[3]; banchan2.append(banchan2_tmp)
        banchan3.append('*')

        if i < 1067:
            kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)
            side_tmp = day_menu[-2]; side.append(side_tmp)
        else:
            kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)
            side_tmp  = day_menu[-1]; side.append(side_tmp)

    else :
        bob_tmp = day_menu[0]; bob.append(bob_tmp)
        gook_tmp = day_menu[1]; gook.append(gook_tmp)
        banchan1_tmp = day_menu[2]; banchan1.append(banchan1_tmp)
        banchan2_tmp = day_menu[3]; banchan2.append(banchan2_tmp)
        banchan3_tmp = day_menu[4]; banchan3.append(banchan3_tmp)

        if i < 1067:
            kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)
            side_tmp = day_menu[-2]; side.append(side_tmp)
        else:
            kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)
            side_tmp  = day_menu[-1]; side.append(side_tmp)


train_dn = train.copy()

train_dn['bob'] = bob
train_dn['gook'] = gook
train_dn['banchan1'] = banchan1
train_dn['banchan2'] = banchan2
train_dn['banchan3'] = banchan3
train_dn['kimchi'] = kimchi
train_dn['side'] = side
train_dn.head()

# test_dn
dinner = []
for day in range(len(test)):
    tmp = test.iloc[day, 9].split(' ') # 공백으로 문자열 구분
    tmp = ' '.join(tmp).split()    # 빈 원소 삭제

    search = '('   # 원산지 정보 삭제
    for menu in tmp:
        if search in menu:
            tmp.remove(menu)

    dinner.append(tmp)

train.iloc[1, 9]

dinner

bob = []; gook = []; banchan1 = []; banchan2 = []; banchan3 = []; kimchi = []; side = []

for i, day_menu in enumerate(dinner):
    if (len(day_menu) < 4 ):
        bob.append('*')
        gook.append('*')
        banchan1.append('*')
        banchan2.append('*')
        banchan3.append('*')

        if i < 1067:
            kimchi.append('*')
            side.append('*')
        else:
            kimchi.append('*')
            side.append('*')

    elif (len(day_menu)==4):
        bob_tmp = day_menu[0]; bob.append(bob_tmp)
        gook_tmp = day_menu[1]; gook.append(gook_tmp)
        banchan1_tmp = day_menu[2]; banchan1.append(banchan1_tmp)
        banchan2_tmp = day_menu[3]; banchan2.append(banchan2_tmp)
        banchan3.append('*')

        if i < 1067:
            kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)
            side_tmp = day_menu[-2]; side.append(side_tmp)
        else:
            kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)
            side_tmp  = day_menu[-1]; side.append(side_tmp)

    else :
        bob_tmp = day_menu[0]; bob.append(bob_tmp)
        gook_tmp = day_menu[1]; gook.append(gook_tmp)
        banchan1_tmp = day_menu[2]; banchan1.append(banchan1_tmp)
        banchan2_tmp = day_menu[3]; banchan2.append(banchan2_tmp)
        banchan3_tmp = day_menu[4]; banchan3.append(banchan3_tmp)

        if i < 1067:
            kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)
            side_tmp = day_menu[-2]; side.append(side_tmp)
        else:
            kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)
            side_tmp  = day_menu[-1]; side.append(side_tmp)


test_dn = test.copy()

test_dn['bob'] = bob
test_dn['gook'] = gook
test_dn['banchan1'] = banchan1
test_dn['banchan2'] = banchan2
test_dn['banchan3'] = banchan3
test_dn['kimchi'] = kimchi
test_dn['side'] = side
test_dn.head()

# train_ln
원재료1 = [
    train_ln["banchan1"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    train_ln["banchan1"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    train_ln["banchan1"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    train_ln["banchan1"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    train_ln["banchan1"].str.contains('오리'),
    train_ln["banchan1"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist1 = ['해산물', '소', '닭',"돼지",'오리','채소']

train_ln['반찬1_원재료'] = np.select(원재료1, choicelist1, default='기타')

원재료2 = [
    train_ln["banchan2"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    train_ln["banchan2"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    train_ln["banchan2"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    train_ln["banchan2"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    train_ln["banchan2"].str.contains('오리'),
    train_ln["banchan2"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist2 = ['해산물', '소', '닭',"돼지",'오리','채소']

train_ln['반찬2_원재료'] = np.select(원재료2, choicelist2, default='기타')

원재료3 = [
    train_ln["banchan3"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    train_ln["banchan3"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    train_ln["banchan3"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    train_ln["banchan3"].str.contains('삽겹|폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    train_ln["banchan3"].str.contains('오리'),
    train_ln["banchan3"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist3 = ['해산물', '소', '닭',"돼지",'오리','채소']

train_ln['반찬3_원재료'] = np.select(원재료3, choicelist3, default='기타')

train_ln

# test_ln
원재료1 = [
    test_ln["banchan1"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    test_ln["banchan1"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    test_ln["banchan1"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    test_ln["banchan1"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    test_ln["banchan1"].str.contains('오리'),
    test_ln["banchan1"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist1 = ['해산물', '소', '닭',"돼지",'오리','채소']

test_ln['반찬1_원재료'] = np.select(원재료1, choicelist1, default='기타')

원재료2 = [
    test_ln["banchan2"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    test_ln["banchan2"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    test_ln["banchan2"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    test_ln["banchan2"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    test_ln["banchan2"].str.contains('오리'),
    test_ln["banchan2"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist2 = ['해산물', '소', '닭',"돼지",'오리','채소']

test_ln['반찬2_원재료'] = np.select(원재료2, choicelist2, default='기타')

원재료3 = [
    test_ln["banchan3"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    test_ln["banchan3"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    test_ln["banchan3"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    test_ln["banchan3"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    test_ln["banchan3"].str.contains('오리'),
    test_ln["banchan3"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist3 = ['해산물', '소', '닭',"돼지",'오리','채소']

test_ln['반찬3_원재료'] = np.select(원재료3, choicelist3, default='기타')

test_ln

# train_dn
원재료1 = [
    train_dn["banchan1"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    train_dn["banchan1"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    train_dn["banchan1"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    train_dn["banchan1"].str.contains('삽겹|폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    train_dn["banchan1"].str.contains('오리'),
    train_dn["banchan1"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist1 = ['해산물', '소', '닭',"돼지",'오리','채소']

train_dn['반찬1_원재료'] = np.select(원재료1, choicelist1, default='기타')

원재료2 = [
    train_dn["banchan2"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    train_dn["banchan2"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    train_dn["banchan2"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    train_dn["banchan2"].str.contains('삽겹|폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    train_dn["banchan2"].str.contains('오리'),
    train_dn["banchan2"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist2 = ['해산물', '소', '닭',"돼지",'오리','채소']

train_dn['반찬2_원재료'] = np.select(원재료2, choicelist2, default='기타')

원재료3 = [
    train_dn["banchan3"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    train_dn["banchan3"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    train_dn["banchan3"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    train_dn["banchan3"].str.contains('삽겹|폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    train_dn["banchan3"].str.contains('오리'),
    train_dn["banchan3"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist3 = ['해산물', '소', '닭',"돼지",'오리','채소']

train_dn['반찬3_원재료'] = np.select(원재료3, choicelist3, default='기타')

train_dn

# test_dn
원재료1 = [
    test_dn["banchan1"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    test_dn["banchan1"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    test_dn["banchan1"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    test_dn["banchan1"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    test_dn["banchan1"].str.contains('오리'),
    test_dn["banchan1"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist1 = ['해산물', '소', '닭',"돼지",'오리','채소']

test_dn['반찬1_원재료'] = np.select(원재료1, choicelist1, default='기타')

원재료2 = [
    test_dn["banchan2"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    test_dn["banchan2"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    test_dn["banchan2"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    test_dn["banchan2"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    test_dn["banchan2"].str.contains('오리'),
    test_dn["banchan2"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist2 = ['해산물', '소', '닭',"돼지",'오리','채소']

test_dn['반찬2_원재료'] = np.select(원재료2, choicelist2, default='기타')

원재료3 = [
    test_dn["banchan3"].str.contains("황태|연어|맛살|골뱅이|열기|조기|탕수어|양장피|홍어|명태|적어|장어|동태|산슬|코다리|가자미|해물|생선|새우|꽁치|갈치|임연수|삼치|고등어|굴비|오징어|쭈꾸미|주꾸미|낙지|문어"),
    test_dn["banchan3"].str.contains('왕갈비|소갈비|장조림|불고기|차돌|육전|너비아니|떡갈비|소|소세|함박|쇠고기|소고기|쇠|갈비'),
    test_dn["banchan3"].str.contains('궁보계정|삼계탕|윙|유린기|깐풍|닭|치킨|후라이드|장각'),
    test_dn["banchan3"].str.contains('폭립|오향장육|동파육|히레카츠|순대|미트볼|등갈비|소세지|목살|탕수육|제육|돈|돼지|두루치기|삼겹|보쌈|족발'),
    test_dn["banchan3"].str.contains('오리'),
    test_dn["banchan3"].str.contains('두부|꼬치산적|고추|양파|부추|고구마|감자|깻잎|샐러드시금치|야채'),
]

choicelist3 = ['해산물', '소', '닭',"돼지",'오리','채소']

test_dn['반찬3_원재료'] = np.select(원재료3, choicelist3, default='기타')

test_dn

train_ln['반찬1_원재료'].value_counts(), train_ln['반찬2_원재료'].value_counts(),train_ln['반찬3_원재료'].value_counts()

train_dn['반찬1_원재료'].value_counts(), train_dn['반찬2_원재료'].value_counts(),train_dn['반찬3_원재료'].value_counts()

train_ln = train_ln[['bob', 'gook', 'banchan1', 'banchan2', 'banchan3', 'kimchi', 'side',
        '반찬1_원재료', '반찬2_원재료', '반찬3_원재료']].copy()
test_ln = test_ln[['bob',
        'gook', 'banchan1', 'banchan2', 'banchan3', 'kimchi', 'side', '반찬1_원재료',
        '반찬2_원재료', '반찬3_원재료']].copy()
train_dn = train_dn[['bob',
        'gook', 'banchan1', 'banchan2', 'banchan3', 'kimchi', 'side', '반찬1_원재료',
        '반찬2_원재료', '반찬3_원재료']].copy()
test_dn = test_dn[['bob',
        'gook', 'banchan1', 'banchan2', 'banchan3', 'kimchi', 'side', '반찬1_원재료',
        '반찬2_원재료', '반찬3_원재료']].copy()

train_ln.columns = ['밥', '국', '반찬1', '반찬2', '반찬3', '김치', '사이드', '반찬1_원재료', '반찬2_원재료', '반찬3_원재료']
test_ln.columns = ['밥', '국', '반찬1', '반찬2', '반찬3', '김치', '사이드', '반찬1_원재료', '반찬2_원재료', '반찬3_원재료']
train_dn.columns = ['밥', '국', '반찬1', '반찬2', '반찬3', '김치', '사이드', '반찬1_원재료', '반찬2_원재료', '반찬3_원재료']
test_dn.columns = ['밥', '국', '반찬1', '반찬2', '반찬3', '김치', '사이드', '반찬1_원재료', '반찬2_원재료', '반찬3_원재료']

train_ln.head()

test_ln.head()

train_dn.head()

test_dn.head()

train.columns

train_ln.columns

train_lunch = pd.concat([train[['연도', '월', '일', '요일', '출근인원', '중식_신메뉴', '휴일전날', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음',
       '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타', '중식메인조리법']],
                         train_ln, train[['중식비율']]], axis=1)

train_lunch.head()

test_lunch = pd.concat([test[['연도', '월', '일', '요일', '출근인원', '중식_신메뉴', '휴일전날', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음',
       '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타', '중식메인조리법']],
                         test_ln], axis=1)

test_lunch.head()

train_dinner = pd.concat([train[['연도', '월', '일', '요일', '출근인원', '석식_신메뉴', '휴일전날', '석식_전', '석식_무침',
       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '석식메인조리법']],
                         train_dn, train[['석식비율']]], axis=1)

train_dinner.head()

test_dinner = pd.concat([test[['연도', '월', '일', '요일', '출근인원', '석식_신메뉴', '휴일전날', '석식_전', '석식_무침',
       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '석식메인조리법']],
                         test_dn], axis=1)

test_dinner.head()

train_lunch.columns, test_lunch.columns, train_dinner.columns, test_dinner.columns

train = train[['일자', '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수',
       '현본사소속재택근무자수','출근인원','휴일전날', '조식메뉴', '중식메뉴', '석식메뉴',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜',
       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침',
       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타',
       '중식메인조리법', '석식메인조리법', '중식계', '석식계', '중식비율', '석식비율', '일강수량(mm)']].copy()

test = test[['일자', '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수',
       '현본사소속재택근무자수','출근인원','휴일전날', '조식메뉴', '중식메뉴', '석식메뉴',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜',
       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침',
       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타',
       '중식메인조리법', '석식메인조리법', '일강수량(mm)']].copy()

"""### 이벤트날 추가"""

# bok1 : 초복 , bok2 : 중복, bok3 : 말복, dongji : 동짓날, uni_test : 수능, parents_day : 어버이날, 축제 : 유등축제
bok1 = ["2016-07-17","2017-07-12", "2018-07-17", "2019-07-12", "2020-07-16"]
bok2 = ["2016-07-27","2017-07-22", "2018-07-27", "2019-07-22", "2020-07-26"]
bok3 = ["2016-08-16","2017-08-11", "2018-08-16", "2019-08-11", "2020-08-15"]
dongji = ["2016-12-21", "2017-12-22", "2018-12-22", "2019-12-22", "2020-12-21"]
uni_test = ["2016-11-17", "2017-11-23", "2018-11-15", "2019-11-14", "2020-12-3", "2021-11-18"]
parents_day = ["2016-05-08", "2017-05-08", "2018-05-08", "2019-05-08", "2020-05-08", "2021-05-08"]
축제 = ['2016-10-01','2016-10-15','2017-10-01','2017-10-16','2018-10-01','2018-10-14','2019-10-01','2019-10-13','2020-11-01','2020-12-31']
storm = ["2019-10-02"]
def event_day(word) :

    lst= []
    for i in train["일자"]:
        if i in word :
            lst.append(1)

        else :
            lst.append(0)
    return lst

train["초복"] = event_day(bok1)
train["중복"] = event_day(bok2)
train["말복"] = event_day(bok3)
train["동지"] = event_day(dongji)
train["수능"] = event_day(uni_test)
train["어버이날"] = event_day(parents_day)
train['유등축제'] = event_day(축제)

train = train[['일자', '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수',
       '현본사소속재택근무자수','출근인원','휴일전날', '초복', '중복', '말복', '동지', '수능', '어버이날','유등축제', '조식메뉴', '중식메뉴', '석식메뉴',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜',
       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침',
       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타',
       '중식메인조리법', '석식메인조리법', '중식계', '석식계', '중식비율', '석식비율', '일강수량(mm)']].copy()

test = test[['일자', '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수',
       '현본사소속재택근무자수','출근인원','휴일전날', '조식메뉴', '중식메뉴', '석식메뉴',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜',
       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침',
       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타',
       '중식메인조리법', '석식메인조리법', '일강수량(mm)']].copy()

"""## 시각화

### 이벤트날에 따른 식수 변화
"""

# ...으로 생략된 모든 메뉴, 컬럼을 출력하는 옵션

pd.set_option('display.max_colwidth', None)
pd.set_option('display.max_columns', None)

"""#### 공휴일 전날
예상: 공휴일 전날은 그렇지 않은 날보다 식수 인원이 적을 것이다.
"""

train.columns

# 점심
holidays_ln = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "중식계", "중식비율", "휴일전날", "일강수량(mm)"]]
holidays_ln

# '휴일 전날'과 '휴일 전날이 아닌 날'의 평균 중식 식사비율 비교
print("휴일 전날", holidays_ln[holidays_ln["휴일전날"]==1].agg({"중식비율":"mean"}))
print("휴일 전날이 아닌 날", holidays_ln[holidays_ln["휴일전날"]==0].agg({"중식비율":"mean"}))

"""- 휴일 전날인 경우 평균 중식 식사비율 : 약 30% (출근 인원 중 점심 식사를 하는 사람의 비율이 30%)
- 휴일 전날이 아닌 경우 평균 중식 식사비율 : 약 40%

=> 휴일 전날은 평균적으로 약 10%p 정도 중식비율이 적음
"""

# 휴일 전날인 경우 중식계 수치기술통계
holidays_ln[holidays_ln["휴일전날"]==1]["중식비율"].describe()

# 휴일 전날이 아닌 경우 중식계 수치기술통계
holidays_ln[holidays_ln["휴일전날"]==0]["중식비율"].describe()

# boxplot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))
sns.boxplot(y=holidays_ln[holidays_ln["휴일전날"]==1]["중식비율"], ax = ax[0]).set(title='휴일 전날 중식비율 분포')
sns.boxplot(y=holidays_ln[holidays_ln["휴일전날"]==0]["중식비율"], ax = ax[1]).set(title='휴일 전날 제외 중식비율 분포')
plt.show();

"""- 휴일 전날의 경우 1Q ~ 3Q 중식비율은 0.25 ~ 0.34
- 휴일전날이 아닌 경우 1Q ~ 3Q 중식비율은 0.34 ~ 0.45

=> 휴일 전날임에도 0.45 이상인 날이 있음. -> why?

=> 휴일 전날이 아님에도 0.2 이하인 날이 있음. -> why?

**1) 휴일 전날임에도 중식을 많이 먹은 이유가 뭘까?**
"""

# 휴일 전날임에도 중식식사비율이 0.45 이상인 날
hl = holidays_ln[holidays_ln["휴일전날"]==1]["중식비율"]
hl.loc[hl > 0.45]

# 평균 점심 식사 비율
round((holidays_ln["중식계"] / holidays_ln["출근인원"]).mean(), 2)

# 2016년 2월 29일 월요일
# 3월 1일 삼일절 전날
# 인기메뉴인 제육볶음이 나온 날

holidays_ln.loc[[17]]

# 2019년 10월 2일 수요일
# 10월 3일 개천절 공휴일 전날
# 이 날은 태풍의 영향으로 구내식당 이용률이 높아서 중식계가 많은 것.
# 일강수량이 무려 139.6mm

holidays_ln.loc[[894]]

# 2019년 10월 4일 금요일
# 10월 3일 개천절 공휴일 다음날, 토요일 전날
# 명확한 이유를 찾지 못함

holidays_ln.loc[[895]]

"""**2) 휴일 전날이 아님에도 중식을 적게 먹은 이유가 뭘까?**"""

# 휴일 전날이 아님에도 중식식사비율이 0.2 이하인 날
hl_not = holidays_ln[holidays_ln["휴일전날"]==0]["중식비율"]
hl_not.loc[hl_not < 0.2]

# 2017년 12월 28일 목요일
holidays_ln.loc[[469]]

# 특이한 점은 12월 29일에 휴가를 더 많이 갔음에도 중식계는 더 높음
# 메뉴 선호도가 떨어져서 그런 것이 아닐까 추정
holidays_ln.iloc[468:471, :]

holidays_ln[holidays_ln["중식메뉴"].str.contains("돼지갈비찜")]["중식비율"].mean()

"""- 돼지갈비찜이 인기없는 메뉴인가?
- => 돼지갈비찜에 관한 데이터프레임 추출하고 시각화하여 확인
"""

train_lunch["일자"] = train["일자"]
train_lunch["중식비율"] = train["중식비율"]
train_lunch.head(2)

galbi  = train_lunch.loc[train_lunch["반찬1"]== "돼지갈비찜", ["일자",'밥', '국',
                                                        '반찬1', '반찬2', '반찬3', '김치', '사이드', "출근인원", "중식비율"]]
galbi['구분'] = (galbi['중식비율'] >= train["중식비율"].mean()).astype(int)

display(galbi["중식비율"].mean())  # 갈비의 중식비율 평균
display(galbi.reset_index(drop=True))

# 돼지갈비찜의 평균 중식비율이 0.33
# 전체 평균 중식비율은 0.37
sns.set_style('whitegrid')
plt.figure(figsize=(20,10))
plt.rcParams['font.family'] = 'AppleGothic'   # 폰트 깨짐 해결

sns.scatterplot(data = galbi, x = "일자", y = '중식비율', hue = "구분" , s =700)
plt.axhline( y =galbi["중식비율"].mean(), ls = ":", c = "Green", alpha = 0.6, label = "돼지갈비찜 중식비율 평균") # 초록색 : 제육볶음 중식비율 평균
plt.axhline( y =train["중식비율"].mean(), ls = "--", c = "Blue", alpha = 0.6, label = "전체 중식비율 평균") # 파란색 : 전체 중식비율 평균
plt.title("돼지갈비찜 중식비율 그래프", fontdict = {'fontsize': 50})
plt.xticks(rotation=45)
plt.legend(["중식비율 평균이상", "중식비율 평균미만"], loc='upper right', fontsize = 12)
plt.show();

"""* 전체 중식비율 평균이 0.38, 돼지갈비찜의 중식비율 평균은 0.32정도이다
* 돼지갈비찜은 나올 때마다 중식비율이 거의 전체 평균 아래에 위치하며 높아도 평균 주위에 있다.
* 돼지갈비찜은 예상과 달리 그닥 인기메뉴가 아니었다.
"""

# 2020년 9월 28일 월요일
# 9월 30일부터 추석연휴 시작이라서 그럴까?
holidays_ln.loc[[1129]]

# 추석 연휴가 시작하기 전날 9월 29일엔 식사운영을 아예 하지 않음. -> 29일은 LH 창립기념일 대체 휴무
# 아마 긴 연휴(창립기념일 + 추석 연휴) 전날이기 때문에 휴가를 낸 사람들이 많았을 것
# 실제로 휴가를 아주 많이 냈었다.
holidays_ln.iloc[1127:1132, :]

# 저녁
holidays_dn = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "석식계", "석식비율", "휴일전날", "일강수량(mm)"]]
holidays_dn

# '휴일 전날'과 '휴일 전날이 아닌 날'의 평균 석식 식사비율 비교
print("휴일 전날", holidays_dn[holidays_dn["휴일전날"]==1].agg({"석식비율":"mean"}))
print("휴일 전날이 아닌 날",holidays_dn[holidays_dn["휴일전날"]==0].agg({"석식비율":"mean"}))

"""- 휴일 전날의 경우 평균 석식 식사비율 : 약 18%
- 휴일전날이 아닌 경우 평균 석식 식사비율 : 약 20%

=> 휴일 전날은 평균적으로 약 2%p 정도 석식비율이 적음

=> 중식보다는 미미한 차이 (중식의 경우 10%p 차이가 났음)
"""

# 휴일 전날인 경우 석식계 수치기술통계
holidays_dn[holidays_dn["휴일전날"]==1]["석식비율"].describe()

# 휴일 전날이 아닌 경우 석식계 수치기술통계
holidays_dn[holidays_dn["휴일전날"]==0]["석식비율"].describe()

# boxplot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))
sns.boxplot(y=holidays_dn[holidays_dn["휴일전날"]==1]["석식비율"], ax = ax[0]).set(title='휴일 전날 석식비율 분포')
sns.boxplot(y=holidays_dn[holidays_dn["휴일전날"]==0]["석식비율"], ax = ax[1]).set(title='휴일 전날 제외 석식비율 분포')
plt.show();

"""- 휴일 전날의 경우 석식비율은 0.15 ~ 0.21
- 휴일전날이 아닌 경우 석식비율은 0.18 ~ 0.23

=> 휴일 전날이 아님에도 0.1 이하인 날이 많음. -> why?

**휴일 전날이 아님에도 석식을 적게 먹은 이유가 뭘까?**
"""

# 휴일 전날이 아님에도 0.1 이하인 날 (0보다는 큼)
hd_not = holidays_dn[holidays_dn["휴일전날"]==0]["석식비율"]
hd_not.loc[(hd_not < 0.1)&(hd_not >0)]

# 휴일 전날이 아님에도 0.1 이하인 날의 인덱스만 추출
hd_not_list = hd_not.loc[(hd_not < 0.1)&(hd_not >0)].index.tolist()
hd_not_list

# 대부분 12월 말 -> 연말이라 저녁 약속이 많아 그런 것으로 추정
# 2020년 9월 28일 -> 연말도 아닌데 왜?
holidays_dn.loc[hd_not_list]

# 2020년 9월 28일은 휴가자수가 굉장히 많은 날
# 추석 연휴가 시작하기 전날 9월 29일엔 식사운영을 아예 하지 않음. -> 창립기념일 대체 휴무
# 아마 긴 연휴를 위해 휴가를 낸 사람들이 많아서?
# 실제로 휴가를 아주 많이 냈었다.
holidays_dn.iloc[1128:1131, :]

"""#### 동지
예상: 동짓날은 그렇지 않은 날보다 식수 인원이 많을 것이다.
"""

# 점심
donji_ln = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "중식계", "중식비율", "동지"]]
donji_ln.head(2)

# 동짓날 점심
donji_ln[donji_ln["동지"]==1]

# '동짓날'과 '동짓날이 아닌 날'의 평균 중식비율 비교
print("동짓날", donji_ln[donji_ln["동지"]==1].agg({"중식비율":"mean"}))
print("동짓날이 아닌 날", donji_ln[donji_ln["동지"]==0].agg({"중식비율":"mean"}))

"""- 동짓날의 경우 평균 중식비율 : 약 40%
- 동짓날이 아닌 경우 평균 중식비율 : 약 37%

=> 동짓날은 평균적으로 약 3%p 정도 중식비율이 많음

=> 하지만, 동짓날에 팥죽과 같은 특별 메뉴로 인해 중식비율이 증가한 것은 아님
"""

# 동짓날에 팥죽이 나온 날과 그 외 다른 날의 평균 중식비율 비교
print("동짓날+팥죽 나온 날", donji_ln[donji_ln["일자"]=='2020-12-21'].agg({"중식비율":"mean"}))
print("그 외 날짜", donji_ln[~(donji_ln["일자"]=='2020-12-21')].agg({"중식비율":"mean"}))

"""- 동짓날+팥죽 나온 날의 평균 중식비율 : 약 56%
- 그 외 날짜의 평균 중식비율 : 약 38%

=> 동짓날에다 팥죽까지 나온 날은 약 18%p 정도 중식비율이 많음

=> 동짓날에 팥죽과 같은 특별 메뉴로 인해 중식비율이 증가한 것이라고 할 수 있음
"""

# 저녁
donji_dn = train[["일자", "본사휴가자수", "출근인원", "석식메뉴", "석식계", "석식비율", "동지"]]
donji_dn.head(2)

# 동짓날 저녁
# 석식에 팥죽이 나온 경우는 없었음 -> 추가 분석을 진행하지 않음
donji_dn[donji_dn["동지"]==1]

"""#### 수능날
예상: 수능날은 그렇지 않은 날보다 식수 인원이 적을 것이다.
"""

# 점심
uni_test_ln = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "중식계", "중식비율", "수능"]]
uni_test_ln.head(2)

# 수능날 점심
uni_test_ln[uni_test_ln["수능"]==1]

# '수능날'과 '수능날이 아닌 날'의 평균 중식비율 비교
print("수능날", uni_test_ln[uni_test_ln["수능"]==1].agg({"중식비율":"mean"}))
print("수능날이 아닌 날", uni_test_ln[uni_test_ln["수능"]==0].agg({"중식비율":"mean"}))

"""- 수능날의 평균 중식비율 : 약 32%
- 수능날이 아닌 날 평균 중식비율 : 약 37%

=> 수능날이 수능날이 아닌 날보다 약 5%p 정도 중식비율이 낮음
"""

# 저녁
uni_test_dn = train[["일자", "본사휴가자수", "본사시간외근무명령서승인건수", "출근인원", "석식메뉴", "석식계", "석식비율", "수능"]]
uni_test_dn.head(2)

# 수능날 저녁에 야근을 많이했을까?
# 평균 본사시간외근무명령서승인건수
# 평균적으로 하루에 274명이 야근을 함
train["본사시간외근무명령서승인건수"].mean()

# 수능날 저녁
# 수능날 저녁은 평균 아근자수인 274명보다 많이 야근을 했음
uni_test_dn[uni_test_dn["수능"]==1]

# '수능날'과 '수능날이 아닌 날'의 평균 석식비율 비교
print("수능날", uni_test_dn[uni_test_dn["수능"]==1].agg({"석식비율":"mean"}))
print("수능날이 아닌 날", uni_test_dn[uni_test_dn["수능"]==0].agg({"석식비율":"mean"}))

"""- 수능날의 평균 석식비율 : 약 21%
- 수능날이 아닌 날 평균 석식비율 : 약 20%

=> 수능날이 수능날이 아닌 날보다 약 1%p 정도 석식비율이 높음

=> 예상과 달리 수능날 석식 비율이 더 높았음

=> 고3 자녀가 없는 직원이 많을수도

=> 수능날은 퇴근시간에 차가 많으니까 구내식당에서 식사를 하고 집에 귀가할수도

=> 수능날 늦게 출근해서 아침을 먹고 와서 점심을 덜 먹음. 늦게 출근해서 야근을 많이 하면서 석식 비율이 생각보다 높았을 것.

#### 어버이날
예상: 어버이날은 그렇지 않은 날보다 식수 인원이 적을 것이다.
"""

# 점심
parentsday_ln = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "중식계", "중식비율", "어버이날"]]
parentsday_ln.head(2)

# 어버이날 점심
parentsday_ln[parentsday_ln["어버이날"]==1]

# '어버이날'과 '어버이날이 아닌 날'의 평균 중식비율 비교
print("어버이날", parentsday_ln[parentsday_ln["어버이날"]==1].agg({"중식비율":"mean"}))
print("어버이날이 아닌 날", parentsday_ln[parentsday_ln["어버이날"]==0].agg({"중식비율":"mean"}))

"""- 어버이날의 평균 중식비율 : 약 40%
- 어버이날이 아닌 날 평균 중식비율 : 약 38%

=> 어버이날이 어버이날이 아닌 날보다 약 2%p 정도 중식비율이 높음
"""

# 저녁
parentsday_dn = train[["일자", "본사휴가자수", "출근인원", "석식메뉴", "석식계", "석식비율", "어버이날"]]
parentsday_dn.head(2)

# 어버이날 저녁
parentsday_dn[parentsday_dn["어버이날"]==1]

# '어버이날'과 '어버이날이 아닌 날'의 평균 석식비율 비교
print("어버이날", parentsday_dn[parentsday_dn["어버이날"]==1].agg({"석식비율":"mean"}))
print("어버이날이 아닌 날", parentsday_dn[parentsday_dn["어버이날"]==0].agg({"석식비율":"mean"}))

"""- 어버이날의 평균 석식비율 : 약 19.3%
- 어버이날이 아닌 날 평균 석식비율 : 약 19.5%

=> 어버이날이 어버이날이 아닌 날보다 약 0.2%p 정도 석식비율이 낮음

=> 예상과 달리 어버이날에 석식비율이 크게 낮아지지 않았음

=> 회사의 위치가 진주. 부모님과 같이 사는 직원이 많이 없을수도.

=> 본인이 어버이 나이대인 직원분들이 많으실수도.

#### 진주유등축제 개막일, 폐막일
예상: 진주유등축제 개막일, 폐막일은 그렇지 않은 날보다 식수 인원이 적을 것이다.
"""

# 점심
festival_ln = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "중식계", "중식비율", "유등축제"]]
festival_ln.head(2)

# 유등축제 개막일, 폐막일의 점심
festival_ln[festival_ln["유등축제"]==1]

# '유등축제'와 '유등축제가 아닌 날'의 평균 중식비율 비교
print("유등축제", festival_ln[festival_ln["유등축제"]==1].agg({"중식비율":"mean"}))
print("유등축제 제외", festival_ln[festival_ln["유등축제"]==0].agg({"중식비율":"mean"}))

"""- 유등축제날의 평균 중식비율 : 약 50%
- 유등축제날이 아닌 날 평균 중식비율 : 약 37%

=> 유등축제날이 유등축제날이 아닌 날보다 약 13%p 정도 중식비율이 높음

=> 메뉴가 제육볶음이라서..? => 제육복음은 평균 중식비율이 0.43.. 매우 인기많은 메뉴임을 확인

- 유등축제 개막일과 페막일에는 드론쇼와 불꽃놀이 등의 행사를 한다.
- 다양한 행사로 직원들이 구내식당 이용이 적을 것이라 생각했다.
- 하지막 오히려 중식비율이 상위권에 속하는 날이었다.
- => 제육볶음이 인기메뉴라고 판단되어 제육볶음에 대한 시각화를 진행하여 확인
"""

jeyook = train_lunch.loc[(train_lunch["반찬1"]== "제육볶음") , ["일자",'밥', '국',
                                                        '반찬1', '반찬2', '반찬3', '김치', '사이드', "출근인원", "중식비율"]].reset_index(drop= True)
jeyook['구분'] = (jeyook['중식비율'] >= train["중식비율"].mean()).astype(int)

display(jeyook["중식비율"].count())
display(jeyook.describe())
display(jeyook.reset_index(drop=True))



sns.set_style('whitegrid')
plt.figure(figsize=(20,10))
plt.rcParams['font.family'] = 'AppleGothic'
sns.scatterplot(data = jeyook, x = "일자", y = '중식비율', hue = "구분" , s =800)
plt.axhline( y =jeyook["중식비율"].mean(), ls = ":", c = "Green", alpha = 0.6, label = "제육볶음 중식비율 평균") # 초록색 : 제육볶음 중식비율 평균
plt.axhline( y =train["중식비율"].mean(), ls = "--", c = "Blue", alpha = 0.6, label = "전체 중식비율 평균") # 파란색 : 전체 중식비율 평균
plt.title("제육볶음의 중식비율 그래프", fontdict = {'fontsize': 50})
plt.ylim([0.3,0.65])
plt.xticks(rotation=45)
plt.legend(["중식비율 평균이상", "중식비율 평균미만"])
plt.show();

"""* 전체 중식비율 평균은 0.38, 제육볶음의 중식비율 평균은 0.45이다.
* 제육볶음의 평균이 전체 평균보다 높은 것만으로도 인기메뉴인걸 알 수 있다.,
* 시각화를 통해 보면 대부분이 전체평균보다 높을 것을 알 수 있다.
* -> 제육볶음을 인기메뉴라고 판단된다.
* 역시 제육은 못 참지~~
"""

# 제육복음 평균 중식비율
train[train["중식메뉴"].str.contains('제육볶음')]["중식비율"].mean()

# 저녁
festival_dn = train[["일자", "본사휴가자수", "출근인원", "석식메뉴", "석식계", "석식비율", "유등축제"]]
festival_dn.head(2)

# 유등축제 개막일, 폐막일의 저녁
festival_dn[festival_dn["유등축제"]==1]

# '유등축제'와 '유등축제가 아닌 날'의 평균 석식비율 비교
print("유등축제", festival_dn[festival_dn["유등축제"]==1].agg({"석식비율":"mean"}))
print("유등축제 제외", festival_dn[festival_dn["유등축제"]==0].agg({"석식비율":"mean"}))

"""- 유등축제날의 평균 석식비율 : 약 21%
- 유등축제날이 아닌 날 평균 석식비율 : 약 20%

=> 유등축제날이 유등축제날이 아닌 날보다 약 1%p 정도 석식비율이 높음

=> 예상과 다른 결과

=> 축제 기간이 길어서 굳이 폐막식, 개막식에 맞춰서 가진 않았을 듯

=> 사람이 몰리는 시간을 피하기 위해 구내식당 석식을 이용했을 것

#### 초복, 중복, 말복
예상: 복날은 삼계탕 특식이 나오는 경우가 많으므로 그렇지 않은 날보다 식수 인원이 많을 것이다.
"""

# 점심
bok_ln = train[["일자", "본사휴가자수", "출근인원", "중식메뉴", "중식계", "중식비율", "초복", "중복", "말복"]]
bok_ln.head(2)

# 초복, 중복, 말복인 날
# 주로 초복인 날에만 삼계탕 특식 제공

bok_ln[(bok_ln["초복"]==1)|(bok_ln["중복"]==1)|(bok_ln["말복"]==1)]

# '초복'와 '초복이 아닌 날'의 평균 중식비율 비교
print("초복", bok_ln[bok_ln["초복"]==1].agg({"중식비율":"mean"}))
print("초복이 아닌 날", bok_ln[bok_ln["초복"]==0].agg({"중식비율":"mean"}))

"""- 초복의 평균 중식비율 : 약 41%
- 초복이 아닌 날 평균 중식비율 : 약 38%

=> 초복이 초복이 아닌 날보다 약 3%p 정도 중식비율이 높음

=> 삼계탕 특식의 효과가 있음
"""

# 저녁
bok_dn = train[["일자", "본사휴가자수", "출근인원", "석식메뉴", "석식계", "석식비율", "초복", "중복", "말복"]]
bok_dn.head(2)

# 초복, 중복, 말복인 날
# 석식에 삼계탕을 제공하는 경우는 없었음

bok_dn[(bok_dn["초복"]==1)|(bok_dn["중복"]==1)|(bok_dn["말복"]==1)]

"""### 연도별, 월별, 요일별 중식비율, 석식비율"""

train.columns

# 연도별 중식비율, 석식비율
yr = train[["연도", "중식비율", "석식비율"]]
yr

# 연도별 중식비율 시각화
yr_gb = train.groupby("연도")[["중식비율", "석식비율"]].mean()
yr_gb

# boxplot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))
sns.barplot(x=yr_gb.index, y=yr_gb["중식비율"], ax = ax[0]).set(title='연도별 중식비율 분포')
sns.barplot(x=yr_gb.index, y=yr_gb["석식비율"], ax = ax[1]).set(title='연도별 석식비율 분포')
plt.show();

"""- 중식 : 19년도를 기점으로 중식비율은 증가 => 코로나로 인해 외부 식사를 하지 않아서 or MZ세대 사원의 특징?(연차가 낮아서 점심때 구내식당이용, 빠른 퇴근)
- 석식 : 꾸준히 하락하고 있음 => 집에 얼른 들어가서 저녁 식사

=> 석식을 먹는 사람들이 점점 줄어듦
"""

# 월별 중식비율, 석식비율
mth = train[["월", "중식비율", "석식비율"]]
mth

# 월별 중식비율 시각화
mth_gb = train.groupby("월")[["중식비율", "석식비율"]].mean()
mth_gb

# boxplot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))
sns.barplot(x=mth_gb.index, y=mth_gb["중식비율"], ax = ax[0]).set(title='월별 중식비율 분포')
sns.barplot(x=mth_gb.index, y=mth_gb["석식비율"], ax = ax[1]).set(title='월별 석식비율 분포')
plt.show();

# 요일별 중식비율, 석식비율
dow = train[["요일", "중식비율", "석식비율"]]
dow

# 요일별 중식비율 시각화
dow_gb = train.groupby("요일")[["중식비율", "석식비율"]].mean()
dow_gb

# boxplot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))
sns.barplot(x=dow_gb.index, y=dow_gb["중식비율"], ax = ax[0]).set(title='요일별 중식비율 분포')
sns.barplot(x=dow_gb.index, y=dow_gb["석식비율"], ax = ax[1]).set(title='요일별 석식비율 분포')
plt.show();

train[train["석식계"] == 0]

# 석식계가 0인 경우를 제외하고 다시 그려보기
train_dn_not_zero = train[train["석식계"] != 0]
dow_gb2 = train_dn_not_zero.groupby("요일")[["중식비율", "석식비율"]].mean()

# boxplot
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))
sns.barplot(x=dow_gb2.index, y=dow_gb2["중식비율"], ax = ax[0]).set(title='요일별 중식비율 분포')
sns.barplot(x=dow_gb2.index, y=dow_gb2["석식비율"], ax = ax[1]).set(title='요일별 석식비율 분포')
plt.show();

"""### 코로나의 영향"""

corona = train[['일자', '본사정원수', '현본사소속재택근무자수', '출근인원', '중식계', '석식계', '중식비율', '석식비율']]
corona

# 코로나 전후 식사인원 비교
# 재택근무자가 처음으로 생긴 날
first_jt_day = corona.loc[(corona['현본사소속재택근무자수'] != 0).idxmax()]["일자"]
first_jt_day

# 재택근무를 시작한 이후의 날짜만 추출
jt_days = corona[corona["일자"] >= first_jt_day]
jt_days

# 코로나 이후 일자별 재택 근무자의 수
# 20년 3월 이후 재택 근무자수가 늘어났음 -> 식수인원의 감소 예측
jt_days.plot(x='일자', y='현본사소속재택근무자수', figsize=[40, 5])
plt.show()

# 전체 일자별 중식계, 석식계 비교
# 예상과 달리 코로나 전후 크게 달라지지 않은 모습
corona.plot(x='일자', y=['중식계', '석식계'], figsize=[40, 5])
plt.show()

# 좀 더 디테일하게 2019년 이후 중식계, 석식계 비교
# 마찬가지로 코로나 전후 크게 달라지지 않은 모습
cut_days = corona[corona["일자"] > '2019-01-01']
cut_days.plot(x='일자', y=['중식계', '석식계'], figsize=[40, 5])
plt.show()

# 재택근무자수가 늘어났음에도 식수인원이 감소하지 않은 이유는?
# 본사정원수가 늘어나서?
corona.plot(x = '일자', y = '본사정원수', figsize = (40, 8), c = "#e74c3c")
plt.title("일자별 본사정원수", fontsize = 20)
plt.show()

# 일자별 출근인원
# 평균선 추가
corona.plot(x = '일자', y = '출근인원', figsize = (40, 8), c = "#e74c3c")
plt.title("일자별 출근인원", fontsize = 20)
plt.show()

# 일자별 본사정원수와 출근인원 수
# 본사정원수가 증가함에 따라 출근인원이 증가했을 것으로 예상
# 그런가...?
corona.plot(x = '일자', y = ['본사정원수', '출근인원'], figsize = (40, 8))
plt.title("일자별 본사정원수와 출근인원", fontsize = 20)
plt.show()

# 재택근무자가 생기기 이전 날들의 중식비율과 석식비율의 평균
before_covid = corona[corona["일자"] < first_jt_day][['중식비율', '석식비율']].mean()
before_covid

# 재택근무자가 생긴 이후 날들의 중식비율과 석식비율의 평균
after_covid = corona[corona["일자"] >= first_jt_day][['중식비율', '석식비율']].mean()
after_covid

# 재탠근무 전후 중식비율, 석식비율 비교
print('중식비율:', '재택근무 이전에는', round(before_covid.loc['중식비율'], 3), ', 재택근무 이후에는', round(after_covid.loc['중식비율'], 3))
print('석식비율:', '재택근무 이전에는', round(before_covid.loc['석식비율'], 3), ', 재택근무 이후에는', round(after_covid.loc['석식비율'], 3))

# 일자별 중식비율
corona.plot(x = '일자', y = '중식비율', figsize = (40, 8))
plt.title("일자별 중식비율", fontsize = 20)
plt.show()

# 일자별 석식비율
corona.plot(x = '일자', y = '석식비율', figsize = (40, 8))
plt.title("일자별 중식비율", fontsize = 20)
plt.show()

# 일자별 중식비율, 석식비율
corona.plot(x = '일자', y = ['중식비율', '석식비율'], figsize = (40, 8))
plt.title("일자별 중식비율과 석식비율", fontsize = 20)
plt.show()

# 일자별 중식계, 석식계 비교
corona.plot(x='일자', y=['중식계', '석식계'], figsize=[40, 5])
plt.title("일자별 중식계과 석식계", fontsize = 20)
plt.show()

train.columns

train_event = train[['휴일전날', '초복', '중복', '말복', '동지',
       '수능', '어버이날', '유등축제', '중식계', '석식계']]
train_event.head(2)

# 내 담당 변수들의 상관관계
df = train_event
mask = np.triu(np.ones_like(df.corr()))
plt.rcParams['font.size'] = 7

fig, ax = plt.subplots(figsize=(12,12))
sns.heatmap(df.corr(),
            annot=True,
            cmap="coolwarm",
            mask = mask)
ax.set_title('Correlation Heatmap', pad = 10)
plt.show();

# 중식계와 석식계에 대한 변수들의 상관계수
train_event_corr = train_event.corr()[["중식계", "석식계"]]
train_event_corr

# 중식계 : 상관계수 절댓값 기준 내림차순
train_event_corr.reindex(train_event_corr['중식계'].abs().sort_values(ascending=False).index)

# 석식계 : 상관계수 절댓값 기준 내림차순
train_event_corr.reindex(train_event_corr['석식계'].abs().sort_values(ascending=False).index)

"""**이벤트날에 따른 식수인원 변화 EDA 분석 결과**

-> '휴일전날'만 ML 피처로 선택.

### 선호도에 따른 메인 메뉴의 조리법 및 식재료

#### 중식 : top10, bottom10 메인 메뉴의 조리법
"""

# 중식
train_lunch.columns

a = train_lunch[['중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림', '중식_구이',
            '중식_훈제', '중식_조리_기타', '중식메인조리법', '밥', '국', '반찬1', '반찬2', '반찬3',
            '김치', '사이드', '반찬1_원재료', '반찬2_원재료', '반찬3_원재료', '중식비율']]
a.head(1)

aa= a.groupby("반찬1")["중식비율"].agg(["count", "mean"])
aa = aa.loc[aa["count"]>1, :] # count가 1 초과인 메뉴들만 고려
aa

# 중식 선호도 top 10 메인메뉴
top10_banchan1_ln=aa['mean'].nlargest(10).index
top10_banchan1_ln=top10_banchan1_ln.tolist()
top10_banchan1_ln

# 중식 선호도 top 10 메인메뉴의 주된 조리법
# 1: 볶음, 2 : 구이, 3:  전, 4 : 찜, 5: 무침, 6: 조림, 7 : 튀김, 8 : 훈제, 9 : 기타
train_lunch.loc[train_lunch["반찬1"].isin(top10_banchan1_ln)]["중식메인조리법"].value_counts()

"""**중식 선호도 상위 top10 반찬1 조리법 빈도수**

1위 : 볶음 28회

2위 : 구이 23회

3위 : 찜 4회

4위 : 기타 3회

5위 : 튀김 3회
"""

# 중식 선호도 bottom 10 메인메뉴
bottom10_banchan1_ln=aa['mean'].nsmallest(10).index
bottom10_banchan1_ln=bottom10_banchan1_ln.tolist()
bottom10_banchan1_ln

# 중식 선호도 bottom 10 메인메뉴의 주된 조리법
# 1: 볶음, 2 : 구이, 3:  전, 4 : 찜, 5: 무침, 6: 조림, 7 : 튀김, 8 : 훈제, 9 : 기타
train_lunch.loc[train_lunch["반찬1"].isin(bottom10_banchan1_ln)]["중식메인조리법"].value_counts()

"""**중식 선호도 하위 bottom10 반찬1 조리법 빈도수**

1위 : 튀김 6회

2위 : 구이 4회

3위 : 기타 3회

4위 : 무침 2회

5위 : 전 3회

#### 중식 : top10, bottom10 메인 메뉴의 식재료
"""

# 중식
a.head(1)

top10_banchan1_ln

# 중식 선호도 top 10 메인메뉴의 원재료
train_lunch.loc[train_lunch["반찬1"].isin(top10_banchan1_ln)]["반찬1_원재료"].value_counts()

"""**중식 선호도 상위 top10 반찬1 원재료 빈도수**

1위 : 소 36회

2위 : 돼지 23회

3위 : 오리 2회
"""

# 중식 선호도 bottom 10 메인메뉴
bottom10_banchan1_ln

# 중식 선호도 bottom 10 메인메뉴의 원재료
train_lunch.loc[train_lunch["반찬1"].isin(bottom10_banchan1_ln)]["반찬1_원재료"].value_counts()

"""**중식 선호도 하위 bottom10 반찬1 원재료 빈도수**

1위 : 해산물 10회

2위 : 닭 6회

3위 : 소 2회

4위 : 돼지 2회

#### 석식 : top10, bottom10 메인 메뉴의 조리법
"""

# 석식
train_dinner.columns

b = train_dinner[['석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이',
            '석식_훈제', '석식_조리_기타', '석식메인조리법', '밥', '국', '반찬1', '반찬2', '반찬3',
            '김치', '사이드', '반찬1_원재료', '반찬2_원재료', '반찬3_원재료', '석식비율']]
b.head(1)

bb= b.groupby("반찬1")["석식비율"].agg(["count", "mean"])
bb = bb.loc[bb["count"]>1, :] # count가 1 초과인 메뉴들만 고려
bb

# 석식 선호도 top 10 메인메뉴
top10_banchan1_dn=bb['mean'].nlargest(10).index
top10_banchan1_dn=top10_banchan1_dn.tolist()
top10_banchan1_dn

# 석식 선호도 top 10 메인메뉴의 주된 조리법
# 1: 볶음, 2 : 구이, 3:  전, 4 : 찜, 5: 무침, 6: 조림, 7 : 튀김, 8 : 훈제, 9 : 기타
train_dinner.loc[train_dinner["반찬1"].isin(top10_banchan1_dn)]["석식메인조리법"].value_counts()

"""**석식 선호도 상위 top10 반찬1 조리법 빈도수**

1위 : 기타 22회

2위 : 구이 2회

3위 : 찜 1회
"""

# 석식 선호도 bottom 10 메인메뉴
bottom10_banchan1_dn=bb['mean'].nsmallest(10).index
bottom10_banchan1_dn=bottom10_banchan1_dn.tolist()
bottom10_banchan1_dn

# 석식 선호도 bottom 10 메인메뉴의 주된 조리법
# 1: 볶음, 2 : 구이, 3:  전, 4 : 찜, 5: 무침, 6: 조림, 7 : 튀김, 8 : 훈제, 9 : 기타
train_dinner.loc[train_dinner["반찬1"].isin(bottom10_banchan1_dn)]["석식메인조리법"].value_counts()

"""**석식 선호도 하위 bottom10 반찬1 조리법 빈도수**

1위 : 기타 62회

2위 : 튀김 5회

3위 : 볶음 1회

4위 : 찜 1회

#### 석식 : top10, bottom10 메인 메뉴의 식재료
"""

# 석식
b.head(1)

top10_banchan1_dn

# 석식 선호도 top 10 메인메뉴의 원재료
train_dinner.loc[train_dinner["반찬1"].isin(top10_banchan1_dn)]["반찬1_원재료"].value_counts()

"""**석식 선호도 상위 top10 반찬1 원재료 빈도수**

1위 : 소 7회

2위 : 해산물 7회

3위 : 기타 7회
"""

# 석식 선호도 bottom 10 메인메뉴
bottom10_banchan1_dn

# 석식 선호도 bottom 10 메인메뉴의 원재료
train_dinner.loc[train_dinner["반찬1"].isin(bottom10_banchan1_dn)]["반찬1_원재료"].value_counts()

"""**중식 선호도 하위 bottom10 반찬1 원재료 빈도수**

1위 : 기타 45회

2위 : 해산물 9회

3위 : 돼지 9회

4위 : 닭 4회

5위 : 소 2회

### 연도별, 월별, 일별, 요일별 가장 인기있는 식재료

#### 연도별 인기 식재료는 무엇일까?

반찬1이 메인 메뉴인 경우가 많아서 반찬1의 원재료로 진행
"""

# train_lunch 컬럼에 중식계가 없어서 생성
# train_dinner 컬럼에 석식계가 없어서 생성
train_lunch['중식계']= train['중식계']
train_dinner['석식계']= train['석식계']

result = train_lunch.groupby(['연도', '반찬1_원재료'])['중식계'].count().reset_index().pivot_table(index=['연도'], columns='반찬1_원재료', values='중식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

result = train_dinner.groupby(['연도', '반찬1_원재료'])['석식계'].count().reset_index().pivot_table(index=['연도'], columns='반찬1_원재료', values='석식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

"""#### 월별 인기 식재료는 무엇일까?"""

result = train_lunch.groupby(['월', '반찬1_원재료'])['중식계'].count().reset_index().pivot_table(index=['월'], columns='반찬1_원재료', values='중식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

result = train_dinner.groupby(['월', '반찬1_원재료'])['석식계'].count().reset_index().pivot_table(index=['월'], columns='반찬1_원재료', values='석식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

"""점심에는 식재료가 '소'인 메뉴를 많이 먹었고, 저녁에는 식재료가 '해산물'인 메뉴를 많이 먹었다.

#### 일별 인기 식재료는 무엇일까?
"""

result = train_lunch.groupby(['일', '반찬1_원재료'])['중식계'].count().reset_index().pivot_table(index=['일'], columns='반찬1_원재료', values='중식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

result = train_dinner.groupby(['일', '반찬1_원재료'])['석식계'].count().reset_index().pivot_table(index=['일'], columns='반찬1_원재료', values='석식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

"""보기 힘들게 나오므로 태블로를 통해 시각화를 진행

#### 요일별 인기 식재료는 무엇일까?
"""

result = train_lunch.groupby(['요일', '반찬1_원재료'])['중식계'].count().reset_index().pivot_table(index=['요일'], columns='반찬1_원재료', values='중식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

result = train_dinner.groupby(['요일', '반찬1_원재료'])['석식계'].count().reset_index().pivot_table(index=['요일'], columns='반찬1_원재료', values='석식계')

# 각 요일에 대한 막대그래프를 내림차순으로 정렬
result = result[result.sum().sort_values(ascending=False).index]

# 결과 시각화
fig, ax = plt.subplots(figsize=(12, 8))
result.plot(kind='bar', ax=ax)

"""화요일, 목요일 저녁에는 기타가 많이 나왔다..?

#### 인기 식재료와의 조합

점심에는 '소'가 많이 나왔다.

그렇다면 무엇과 함께 나올까?
"""

# 반찬1의 원재료가 '소'일때 반찬2와 반찬3의 원재료

lunch1 = train_lunch[train_lunch['반찬1_원재료']=='소']
lunch1.groupby('반찬2_원재료')['중식계'].agg(['count']).sort_values('count', ascending = False).plot(kind='bar')
lunch1.groupby('반찬3_원재료')['중식계'].agg(['count']).sort_values('count', ascending = False).plot(kind='bar')

"""아무래도 반찬1이 메인메뉴인 경우가 많다보니 기타 항목이 많이 나오는 모습을 보여준다.

그렇다면 반찬1이 기타일때는 어떨까?
"""

# 반찬1의 원재료가 '기타'일때 반찬2와 반찬3의 원재료
lunch2 = train_lunch[train_lunch['반찬1_원재료']=='기타']
lunch2.groupby('반찬2_원재료')['중식계'].agg(['count']).sort_values('count', ascending = False).plot(kind='bar')
lunch2.groupby('반찬3_원재료')['중식계'].agg(['count']).sort_values('count', ascending = False).plot(kind='bar')

"""반찬1이 기타인 경우는 그렇게 많지 않을 뿐더러 반찬1이 기타일 때는 밥이나 국에서 특식이 나오는 경우가 많았다.

![image.png](attachment:image.png)

비빔밥, 갈비탕, 낙지비빔밥, 카레덮밥 등...

### 조리법별에 따른 식수인원 분석
#### 조리법별
"""

## 숫자를 조리법으로 변환
how_train = train[['중식메인조리법','석식메인조리법','중식비율','석식비율']]
how_test = test[['중식메인조리법','석식메인조리법']]
how = {
    1: '볶음',
    2: '구이',
    3: '전',
    4: '찜',
    5: '무침',# 샐러드 포함
    6: '조림',
    7: '튀김',
    8: '훈제',
    9: '기타',
}
how_test['중식메인조리법_k'] = how_test['중식메인조리법'].copy().map(how)
how_test['석식메인조리법_k'] = how_test['석식메인조리법'].copy().map(how)
how_train['중식메인조리법_k'] = how_train['중식메인조리법'].copy().map(how)
how_train['석식메인조리법_k'] = how_train['석식메인조리법'].copy().map(how)
how_test.head(10)

# train - 중식메인조리법 1회 평균 중식계,석식계 수요값
sort_train = how_train.groupby('중식메인조리법_k').agg({'중식비율':'mean',
                                                '석식비율':'mean'})

sort_train

"""#### 메인조리법 별 : 많이 나온 수
##### 총기간
"""

# train-'중식'메인조리법
plt.title('중식메인조리법-train')
sns.countplot(data=how_train,x='중식메인조리법_k',order=how_train['중식메인조리법_k'].value_counts().index);

# test
plt.title('중식메인조리법-test')
sns.countplot(data=how_test,x='중식메인조리법_k',order=how_test['중식메인조리법_k'].value_counts().index);

# train-'석식'메인조리법
plt.title('석식메인조리법-train')
sns.countplot(data=how_train,x='석식메인조리법_k',order=how_train['석식메인조리법_k'].value_counts().index);

# test-'석식'메인조리법
plt.title('중식석식조리법-test')
sns.countplot(data=how_test,x='석식메인조리법_k',order=how_test['석식메인조리법_k'].value_counts().index);

"""##### 조리법에 따른 1회평균 중식계,석식계 수요값
- 평균값
    - 중식비율 : 0.3780299
    - 석식비율 : 0.195630
"""

sort_train.describe()

# 중식비율
plt.title('조리별 1회평균 중식비율')
sort_train['중식비율'].sort_values(ascending=False).plot.bar(rot='0');
# 중식비율 평균값
plt.axhline(y=0.378029, color='red', linewidth=1, linestyle='--', label='120')
## 훈제,볶음,구이가 평균이상의 수요를 보였다.

# 석식비율
plt.title('조리별 1회평균 석식비율')
sort_train['석식비율'].sort_values(ascending=False).plot.bar(rot='0');
# 석식비율 평균값
plt.axhline(y=0.195630, color='red', linewidth=1, linestyle='--', label='120')
# 훈제,볶음,구이,조림,찜이 평균이상의 수요를 보였다.

"""##### '가장많이 사용한 식재료' 를 어떤방식으로 가장많이 조리했는가
[train]
- 중식: 소
- 석식: 해산물
"""

# 가장 많이 사용한 식재료 - 중식)'소' : 반찬1의 원재료가 '소'인 아이들을 찾기
## 중식
day_train = pd.concat([train[['일자','연도','월','일','요일']],how_train],axis=1)
cow = pd.concat([train_lunch,day_train['중식메인조리법_k']],axis=1)

plt.title('원재료:[소] 조리방법')
cow.loc[cow['반찬1_원재료']=='소'].groupby('중식메인조리법_k')['중식메인조리법_k'].count().sort_values(ascending=False).plot.bar(rot=0)

# 가장 많이 사용한 식재료 - 석식)'해산물' : 반찬1의 원재료가 '해산물'인 아이들을 찾기
## 석식
plt.title('원재료:[해산물] 조리방법')
sea = pd.concat([train_dinner,day_train['석식메인조리법_k']],axis=1)
sea.loc[sea['반찬1_원재료']=='해산물'].groupby('석식메인조리법_k')['석식메인조리법_k'].count().sort_values(ascending=False).plot.bar(rot=0)

"""### 피처간 상관관계 분석

#### 일자 분리 파생변수 상관관계 분석
"""

# 연도, 월, 일, 요일 등의 상관관계
a = train[['일자', '연도', '월', '일', '요일', '본사정원수',  '본사휴가자수','본사시간외근무명령서승인건수',
       '출근인원', '중식계', '석식계', "중식비율", "석식비율"]]

mask = np.triu(np.ones_like(a.corr(), dtype=np.bool))
plt.rcParams['font.size'] = 15

fig, ax = plt.subplots(figsize=(16, 5))
sns.heatmap(a.corr(),
            annot=True, fmt = ".02f",
            cmap="RdBu",
            mask = mask)

"""* 요일과 중식계, 중식비율이 큰 음의 상관관계를 가진다.
* 본사정원수와 요일은 큰 양의 상관관계를 가진다.
* 야근자수가 석식계와 상관관계가 있을 것이라고 생각했지만 의외로 중식계와도 석식계만큼의 상관관계를 이룬다.

#### 신메뉴와 조리법 파생변수 상관관계 분석
"""

# 신메뉴와 조리법의 상관관계
a = train[['일자', '연도', '월', '일', '요일', '본사정원수',  '본사시간외근무명령서승인건수',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜',
       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타',
       '중식메인조리법', '석식메인조리법', '중식계', '석식계', "중식비율", "석식비율"]]

mask = np.triu(np.ones_like(a.corr(), dtype=np.bool))
plt.rcParams['font.size'] = 15

fig, ax = plt.subplots(figsize=(16, 5))
sns.heatmap(a.corr(),
            annot=True, fmt = ".01f",
            cmap="RdBu",
            mask = mask);

"""* 대부분의 조리법이 상관 관계가 없다.
* 중식메인조리법과 중식_튀김이 양의 상관관계,
* 중식_볶음이 음의 상관관계,
* 중식_구이도 음의 상관관계를 보인다.

#### 이벤트날 상관관계 분석
"""

## 이벤트날의 상관관계
a = train[['일자', '본사휴가자수','출근인원','휴일전날', '초복', '중복', '말복', '동지', '수능', '어버이날','유등축제',
       '중식_신메뉴', '석식_신메뉴',
    '중식계', '석식계', "중식비율", "석식비율"]]

mask = np.triu(np.ones_like(a.corr(), dtype=np.bool))
plt.rcParams['font.size'] = 15

fig, ax = plt.subplots(figsize=(16, 5))
sns.heatmap(a.corr(),
            annot=True, fmt = ".02f",
            cmap="RdBu",
            mask = mask)

"""* 다른 이벤트날들은 다 상관성이 없어보이는데 동지만 조금 더 높은 상관성을 보인다.
* 석식 신메뉴와 동지의 상관성으로 보아 동짓날 석식 신메뉴로 팥죽이 나오지 않았을까 생각된다.
* 휴가자수는 휴일전날과 양의 상관관계를 이루고, 출근인원과 음의 상관관계를 이룬다.
* 다른 이벤트날들이 상관계수가 낮게 나오는 것은 데이터의 양이 적기 때문이라고 판단된다.

### 메뉴별 분석
"""

menu_train_ln = train_lunch.copy()
menu_train_ln =menu_train_ln[['연도', '월', '일', '요일', '출근인원', '밥', '국', '반찬1', '반찬2', '반찬3', '김치', '사이드','중식비율']]
menu_train_ln = pd.concat([train['일자'], menu_train_ln], axis = 1)
menu_train_ln.head()

월 = menu_train_ln.groupby(['요일', '반찬1']).count().sort_values(by = '중식비율',  ascending = 0).loc[1, :].head(5)
화 = menu_train_ln.groupby(['요일', '반찬1']).count().sort_values(by = '중식비율',  ascending = 0).loc[2, :].head(5)
수 = menu_train_ln.groupby(['요일', '반찬1']).count().sort_values(by = '중식비율',  ascending = 0).loc[3, :].head(5)
목 = menu_train_ln.groupby(['요일', '반찬1']).count().sort_values(by = '중식비율',  ascending = 0).loc[4, :].head(5)
금 = menu_train_ln.groupby(['요일', '반찬1']).count().sort_values(by = '중식비율',  ascending = 0).loc[5, :].head(5)

#sns.barplot(월['중식비율'], x = '반찬')
#월['중식비율'].plot(kind = 'bar')
plt.figure(figsize = (16,8))

plt.subplot(3,2,1)
plt.bar(월.index,월['중식비율'])
plt.title('월요일')

plt.subplot(3,2,2)
plt.bar(화.index,화['중식비율'])
plt.title('화요일')

plt.figure(figsize = (16,8))

plt.subplot(3,2,1)
plt.bar(수.index,수['중식비율'])
plt.title('수요일')

plt.subplot(3,2,2)
plt.bar(목.index,목['중식비율'])
plt.title('목요일')


plt.figure(figsize = (16,3))

plt.subplot(1,2,1)
plt.bar(금.index,금['중식비율'])
plt.title('금요일')

"""####많이 나온 메뉴와 중식 비율의 관계"""

df_gook = menu_train_ln.groupby(['국'], as_index = False)['중식비율'].agg(['count', 'mean'])
df_gook.sort_values(by = 'count', ascending = False)
df_gook.corr()

"""국이 자주 나오는 것과 중식 비율 간의 상관관계는 가난함,,

#### 많이 나온 상위 3가지 국에 대한 시계열추세
"""

a = menu_train_ln[menu_train_ln['국'] == '맑은국']
a['일자'].astype('str')
a.head(10)

a.loc[a['국'] == '맑은국', '밥'].unique()
#맑은 국이 나온 날은 특밥

a.plot(kind ='bar', y = '중식비율', x = '일자')
#유난히 10/10일의 중식계 수가 많은 이유는 긴 연휴가 끝난 날이라 그런 듯함

menu_train_ln[menu_train_ln['국'] == '콩나물국'].head()

a = menu_train_ln[menu_train_ln['국'] == '콩나물국']
a['일자'].astype('str')
a.plot(kind ='bar', y = '중식비율', x = '일자')

a = menu_train_ln[menu_train_ln['국'] == '된장찌개']
a['일자'].astype('str')
a.plot(kind ='bar', y = '중식비율', x = '일자')

"""#### 많이 나온 상위 3가지 반찬1에 대한 시계열추세  """

df_banchan1 = menu_train_ln.groupby(['반찬1'], as_index = False)['중식비율'].agg(['count', 'mean'])
df_banchan1.sort_values(by = 'count', ascending = False)

df_banchan1.corr()

"""메뉴가 많이 나오는 것과 중식 비율의 상관관계는 0에 가까움움"""

a = menu_train_ln[menu_train_ln['반찬1'] == '오징어볶음']
a['일자'].astype('str')
a.head()

a.plot(kind ='bar', y = '중식비율', x = '일자')

a = menu_train_ln[menu_train_ln['반찬1'] == '오징어볶음']
a['일자'].astype('str')
a.plot(kind ='bar', y = '중식비율', x = '일자')

a = menu_train_ln[menu_train_ln['반찬1'] == '버섯불고기']
a['일자'].astype('str')
a.plot(kind ='bar', y = '중식비율', x = '일자')

"""제일 많이 나오는 메인 반찬과 국 상위 3종에 대한 추세 분석:
그래프 상으로 추세에 규칙이 발견되지는 않았음

## 머신러닝 진행

### ml용 df 재정비
- ml_train_ln
- ml_test_ln
- ml_train_dn
- ml_test_dn
- 범주형 다 뺴야함
- ex.columns = [ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "중식계",
       '일강수량(mm)']
"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "중식계",
       '일강수량(mm)']]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "석식계",
       '일강수량(mm)']]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]

"""#### 중식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                test_size = 0.1,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape

"""#### 석식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                 test_size = 0.1,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape

"""#### LightGBM"""

import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(max_depth=5)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(max_depth=3)
model_lgbm_dn

"""#### 중식"""

from sklearn.model_selection import RandomizedSearchCV

param_distributions = {"n_estimators": np.random.randint(150, 300, 10),
                       "learning_rate": np.random.uniform(low=0.2, high=0.3, size=20),
#                        "max_depth" :np.random.randint(2, 5, 1)
                      }
reg_ln = RandomizedSearchCV(model_lgbm_ln,
                         param_distributions=param_distributions,
                         n_iter=5,
                         scoring= "neg_mean_absolute_error",
                         cv=5, verbose=1, n_jobs=-1,
                         random_state=42)
reg_ln.fit(X_train_ln, y_train_ln)

# 최적 모델 찾기
best_model = reg_ln.best_estimator_
best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln.best_estimator_).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]

"""#### 석식"""

from sklearn.model_selection import RandomizedSearchCV

param_distributions = {"n_estimators": np.random.randint(150,300, 10),
                       "learning_rate": np.random.uniform(low=0.2, high=0.3, size=20),
#                         "max_depth" :np.random.randint(3, 5, 1)
                      }
reg_dn = RandomizedSearchCV(model_lgbm_dn,
                         param_distributions=param_distributions,
                         n_iter=5,
                         scoring="neg_mean_absolute_error",
                         cv=5, verbose=1, n_jobs=-1,
                         random_state=42)
reg_dn.fit(X_train_dn, y_train_dn)

# 최적 모델 찾기
best_model = reg_dn.best_estimator_
best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn.best_estimator_).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]

"""#### 제출"""

# 캐글에 제출
file_name = f'sub_lgbm_{reg_ln.best_score_}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""### 이상치 제거 후 진행"""

strange = ["2016-02-29", "2017-12-28", "2020-09-28"]

train_st = train.loc[~train["일자"].isin(strange), :]
train_st

ml_train_st_ln = train_st[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "중식계",
       '일강수량(mm)']]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

ml_x_st_ln = ml_train_ln.drop(columns = "중식계")
ml_y_st_ln = ml_train_ln["중식계"]

ml_train_st_dn = train_st[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "석식계",
       '일강수량(mm)']]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

ml_x_st_dn = ml_train_dn.drop(columns = "석식계")
ml_y_st_dn = ml_train_dn["석식계"]

"""#### 중식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape

"""#### 석식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape

"""#### LightGBM"""

# n_estimators=435, max_depth=1, learning_rate=0.1, random_state=42
import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor()
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor()
model_lgbm_dn

"""#### 중식"""

from sklearn.model_selection import RandomizedSearchCV

param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
                       "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
                       "max_depth" : np.random.randint(1, 15, 1)
                      }
reg_ln = RandomizedSearchCV(model_lgbm_ln,
                         param_distributions=param_distributions,
                         n_iter=5,
                         scoring= "neg_mean_absolute_error",
                         cv=15, verbose=1, n_jobs=-1,
                         random_state=42)
reg_ln.fit(X_train_ln, y_train_ln)

# 최적 모델 찾기
best_model = reg_ln.best_estimator_
best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln.best_estimator_).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]

"""#### 석식"""

from sklearn.model_selection import RandomizedSearchCV

param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
                       "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
                       "max_depth" : np.random.randint(1, 15, 1)
                      }
reg_dn = RandomizedSearchCV(model_lgbm_dn,
                         param_distributions=param_distributions,
                         n_iter=5,
                         scoring="neg_mean_absolute_error",
                         cv=15, verbose=1, n_jobs=-1,
                         random_state=42)
reg_dn.fit(X_train_dn, y_train_dn)

# 최적 모델 찾기
best_model = reg_dn.best_estimator_
best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn.best_estimator_).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]

"""#### 제출"""

# 캐글에 제출
file_name = f'sub_lgbm_{reg_ln.best_score_}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)

"""### 피처 로그 변화 후 진행"""

ml_train_ln.hist(figsize= (20,20))

strange = ["2016-02-29", "2017-12-28", "2020-09-28"]

train_st = train.loc[~train["일자"].isin(strange), :]
train_st

ml_train_st_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "중식계",
       '일강수량(mm)']]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

lst_ln = [ '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '중식메인조리법', '석식메인조리법','일강수량(mm)']

for i in lst_ln :
    ml_train_st_ln[f"{i}_log1p"] = np.log1p(ml_train_st_ln[i])
    ml_train_st_ln = ml_train_st_ln.drop(columns=i)
    ml_test_ln[f"{i}_log1p"] = np.log1p(ml_test_ln[i])
    ml_test_ln = ml_test_ln.drop(columns=i)
ml_train_st_ln.info()
display(ml_train_st_ln.columns)

ml_x_ln = ml_train_st_ln.drop(columns = "중식계")
ml_y_ln = ml_train_st_ln["중식계"]

ml_train_st_ln.hist(figsize = (20,20))

ml_train_st_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "석식계",
       '일강수량(mm)']]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

lst_dn = [ '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '중식메인조리법', '석식메인조리법','일강수량(mm)']


for i in lst_dn :
    ml_train_st_dn[f"{i}_log1p"] = np.log1p(ml_train_st_dn[i])
    ml_train_st_dn = ml_train_st_dn.drop(columns=i)
    ml_test_dn[f"{i}_log1p"] = np.log1p(ml_test_dn[i])
    ml_test_dn = ml_test_dn.drop(columns=i)
ml_train_ln.info()

ml_x_dn = ml_train_st_dn.drop(columns = "석식계")
ml_y_dn = ml_train_st_dn["석식계"]

"""#### 중식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape

"""#### 석식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape

"""#### LightGBM"""

import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor()
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor()
model_lgbm_dn

"""#### 중식"""

from sklearn.model_selection import RandomizedSearchCV

param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
                       "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
                      }
reg_ln = RandomizedSearchCV(model_lgbm_ln,
                         param_distributions=param_distributions,
                         n_iter=5,
                         scoring= "neg_mean_absolute_error",
                         cv=10, verbose=1, n_jobs=-1,
                         random_state=42)
reg_ln.fit(X_train_ln, y_train_ln)

# 최적 모델 찾기
best_model = reg_ln.best_estimator_
best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln.best_estimator_).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]

"""#### 석식"""

from sklearn.model_selection import RandomizedSearchCV

param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
                       "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
                      }
reg_dn = RandomizedSearchCV(model_lgbm_dn,
                         param_distributions=param_distributions,
                         n_iter=5,
                         scoring="neg_mean_absolute_error",
                         cv=10, verbose=1, n_jobs=-1,
                         random_state=42)
reg_dn.fit(X_train_dn, y_train_dn)

# 최적 모델 찾기
best_model = reg_dn.best_estimator_
best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn.best_estimator_).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]

"""#### 제출"""

# 캐글에 제출
file_name = f'sub_lgbm_{reg_ln.best_score_}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)

"""### GridSearchCV로 진행"""



ml_train_ln.hist(figsize= (20,20))

strange = ["2016-02-29", "2017-12-28", "2020-09-28"]

train_st = train.loc[~train["일자"].isin(strange), :]
train_st

ml_train_st_ln = train_st[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "중식계",
       '일강수량(mm)']]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

lst_ln = [ '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '중식메인조리법', '석식메인조리법','일강수량(mm)']

for i in lst_ln :
    ml_train_st_ln[f"{i}_log1p"] = np.log1p(ml_train_st_ln[i])
    ml_train_st_ln = ml_train_st_ln.drop(columns=i)
    ml_test_ln[f"{i}_log1p"] = np.log1p(ml_test_ln[i])
    ml_test_ln = ml_test_ln.drop(columns=i)
ml_train_st_ln.info()
display(ml_train_st_ln.columns)

ml_x_ln = ml_train_st_ln.drop(columns = "중식계")
ml_y_ln = ml_train_st_ln["중식계"]

ml_train_st_ln.hist(figsize = (20,20))

ml_train_st_dn = train_st[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법', "석식계",
       '일강수량(mm)']]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '휴일전날',
       '중식_신메뉴', '석식_신메뉴', '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
       '중식_구이', '중식_훈제', '중식_조리_기타', '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
       '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '중식메인조리법', '석식메인조리법',
       '일강수량(mm)']]

lst_dn = [ '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', '출근인원', '중식메인조리법', '석식메인조리법','일강수량(mm)']


for i in lst_dn :
    ml_train_st_dn[f"{i}_log1p"] = np.log1p(ml_train_st_dn[i])
    ml_train_st_dn = ml_train_st_dn.drop(columns=i)
    ml_test_dn[f"{i}_log1p"] = np.log1p(ml_test_dn[i])
    ml_test_dn = ml_test_dn.drop(columns=i)
ml_train_ln.info()

ml_x_dn = ml_train_st_dn.drop(columns = "석식계")
ml_y_dn = ml_train_st_dn["석식계"]

"""#### 중식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape

"""#### 석식계 세트 나누기"""

from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape

"""#### LightGBM"""

import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor()
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor()
model_lgbm_dn

"""#### 중식"""

parameters = {
    'n_estimators': (100,150,200,250, 300,350, 400, 450, 500),
    'depth': (None,5, 10,15,20,25,30),
    'learning_rate': (0.1,0.15,0.2,0.25,0.3),
#     'min_child_samples': (30,35,40,45,50)
}
parameters

import sklearn
sklearn.metrics.SCORERS.keys()

from sklearn.model_selection import GridSearchCV

reg_ln = GridSearchCV(model_lgbm_ln, parameters, n_jobs = -1, cv = 10, verbose = 2,
            scoring = "neg_mean_absolute_error")
reg_ln.fit(X_train_ln, y_train_ln)

# 최적 모델 찾기
best_model = reg_ln.best_estimator_
best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln.best_estimator_).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]

"""#### 석식"""

parameters = {
    'n_estimators': (100,150,200,250, 300,350, 400, 450, 500),
    'depth': (None,5, 10,15,20,25,30),
    'learning_rate': (0.1,0.15,0.2,0.25,0.3),
#     'min_child_samples': (30,35,40,45,50)
}
parameters

import sklearn
sklearn.metrics.SCORERS.keys()

from sklearn.model_selection import GridSearchCV

reg_dn = GridSearchCV(model_lgbm_dn, parameters, n_jobs = -1, cv = 10, verbose = 2,
            scoring = "neg_mean_absolute_error")
reg_dn.fit(X_train_dn, y_train_dn)

# 최적 모델 찾기
best_model = reg_dn.best_estimator_
best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn.best_estimator_).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]

"""#### 제출"""

# 캐글에 제출
file_name = f'sub_lgbm_grid_{reg_ln.best_score_}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)





train.shape, test.shape

train.columns, test.columns

"""# 원본

## 데이터셋
"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]

"""## 데이터셋 나누기"""

from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                test_size = 0.1,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape

from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                 test_size = 0.1,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape

"""## LightGBM"""

import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

"""## 중식"""

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



"""## 석식"""

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]

"""## 제출"""

# 캐글에 제출
file_name = f'1_원본_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""# 이상치 제거"""

strange = ["2016-02-29", "2017-12-28", "2020-09-28"]

train_st = train.loc[~train["일자"].isin(strange), :]
train_st.shape, train.shape

ml_train_st_ln = train_st[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수']]

ml_x_st_ln = ml_train_ln.drop(columns = "중식계")
ml_y_st_ln = ml_train_ln["중식계"]

ml_train_st_dn = train_st[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수']]

ml_x_st_dn = ml_train_dn.drop(columns = "석식계")
ml_y_st_dn = ml_train_dn["석식계"]



from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_st_ln, ml_y_st_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape



from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_st_dn, ml_y_st_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape



# n_estimators=435, max_depth=1, learning_rate=0.1, random_state=42
import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]



# 캐글에 제출
file_name = f'2_이상치제거_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""# 휴일전날 추가"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '휴일전날', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '휴일전날']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '휴일전날', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '휴일전날']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]



from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape



from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape



import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_ln = RandomizedSearchCV(model_lgbm_ln,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring= "neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_ln.fit(X_train_ln, y_train_ln)

# # 최적 모델 찾기
# best_model = reg_ln.best_estimator_
# best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

# reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_dn = RandomizedSearchCV(model_lgbm_dn,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring="neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_dn.fit(X_train_dn, y_train_dn)

# # 최적 모델 찾기
# best_model = reg_dn.best_estimator_
# best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

# reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]



# 캐글에 제출
file_name = f'3_휴일전날_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""# 신메뉴"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '중식_신메뉴', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '중식_신메뉴']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '석식_신메뉴', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '석식_신메뉴']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]



from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape



from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape



# n_estimators=435, max_depth=1, learning_rate=0.1, random_state=42
import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_ln = RandomizedSearchCV(model_lgbm_ln,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring= "neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_ln.fit(X_train_ln, y_train_ln)

# # 최적 모델 찾기
# best_model = reg_ln.best_estimator_
# best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

# reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_dn = RandomizedSearchCV(model_lgbm_dn,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring="neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_dn.fit(X_train_dn, y_train_dn)

# # 최적 모델 찾기
# best_model = reg_dn.best_estimator_
# best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

# reg_dn.best_score_

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]



# 캐글에 제출
file_name = f'4_신메뉴_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""# 조리법"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
 '중식_구이', '중식_훈제', '중식_조리_기타', '중식메인조리법', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
 '중식_구이', '중식_훈제', '중식_조리_기타', '중식메인조리법']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
 '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '석식메인조리법', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음',
 '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타', '석식메인조리법']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]



from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape



from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape



# n_estimators=435, max_depth=1, learning_rate=0.1, random_state=42
import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_ln = RandomizedSearchCV(model_lgbm_ln,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring= "neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_ln.fit(X_train_ln, y_train_ln)

# # 최적 모델 찾기
# best_model = reg_ln.best_estimator_
# best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

# reg_ln.best_score_

# predict
y_pred_lgbm_ln = (reg_ln).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_dn = RandomizedSearchCV(model_lgbm_dn,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring="neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_dn.fit(X_train_dn, y_train_dn)

# # 최적 모델 찾기
# best_model = reg_dn.best_estimator_
# best_model

# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]



# 캐글에 제출
file_name = f'5_조리법_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""# 일강수량"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '일강수량(mm)', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '일강수량(mm)']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '일강수량(mm)', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                  '일강수량(mm)']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]



from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape



from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape



# n_estimators=435, max_depth=1, learning_rate=0.1, random_state=42
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

# predict
y_pred_lgbm_ln = (reg_ln).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]



# 캐글에 제출
file_name = f'6_강수량_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)



"""# 전체 파생변수"""

ml_train_ln = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '휴일전날', '중식_신메뉴',  '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
 '중식_구이', '중식_훈제', '중식_조리_기타', '중식메인조리법', '일강수량(mm)', "중식계"]]

ml_test_ln = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '휴일전날', '중식_신메뉴',  '중식_전', '중식_무침', '중식_튀김', '중식_찜', '중식_볶음', '중식_조림',
 '중식_구이', '중식_훈제', '중식_조리_기타', '중식메인조리법', '일강수량(mm)']]

ml_x_ln = ml_train_ln.drop(columns = "중식계")
ml_y_ln = ml_train_ln["중식계"]

ml_train_dn = train[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '휴일전날', '석식_신메뉴',  '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음', '석식_조림',
 '석식_구이', '석식_훈제', '석식_조리_기타', '석식메인조리법', '일강수량(mm)', "석식계"]]

ml_test_dn = test[[ '연도', '월', '일', '요일', '본사정원수', '본사휴가자수', '본사출장자수',
       '본사시간외근무명령서승인건수', '현본사소속재택근무자수',
                           '휴일전날', '석식_신메뉴',  '석식_전', '석식_무침', '석식_튀김', '석식_찜', '석식_볶음', '석식_조림',
 '석식_구이', '석식_훈제', '석식_조리_기타', '석식메인조리법', '일강수량(mm)']]

ml_x_dn = ml_train_dn.drop(columns = "석식계")
ml_y_dn = ml_train_dn["석식계"]



from sklearn.model_selection import train_test_split

X_train_ln, X_test_ln, y_train_ln, y_test_ln = train_test_split(ml_x_ln, ml_y_ln,
                                                                random_state = 42)
X_train_ln.shape, X_test_ln.shape, y_train_ln.shape, y_test_ln.shape



from sklearn.model_selection import train_test_split

X_train_dn, X_test_dn, y_train_dn, y_test_dn = train_test_split(ml_x_dn, ml_y_dn,
                                                                random_state = 42)
X_train_dn.shape, X_test_dn.shape, y_train_dn.shape, y_test_dn.shape



# n_estimators=435, max_depth=1, learning_rate=0.1, random_state=42
import lightgbm
model_lgbm_ln = lightgbm.LGBMRegressor(learning_rate=0.29452109269688104, max_depth=1, n_estimators=154,
              random_state=42)
model_lgbm_ln

model_lgbm_dn = lightgbm.LGBMRegressor(learning_rate=0.24524736053998358, max_depth=1, n_estimators=234,
              random_state=42)
model_lgbm_dn

reg_ln = model_lgbm_ln
reg_ln.fit(X_train_ln, y_train_ln)

reg_dn = model_lgbm_dn
reg_dn.fit(X_train_dn, y_train_dn)

# from sklearn.model_selection import RandomizedSearchCV

# param_distributions = {"n_estimators": np.random.randint(100, 1000, 5),
#                        "learning_rate": np.random.uniform(low=0.05, high=0.3, size=10),
#                        "max_depth" : np.random.randint(1, 15, 1)
#                       }
# reg_ln = RandomizedSearchCV(model_lgbm_ln,
#                          param_distributions=param_distributions,
#                          n_iter=5,
#                          scoring= "neg_mean_absolute_error",
#                          cv=15, verbose=1, n_jobs=-1,
#                          random_state=42)
# reg_ln.fit(X_train_ln, y_train_ln)

# # 최적 모델 찾기
# best_model = reg_ln.best_estimator_
# best_model

# valid score
score_lgbm_ln = reg_ln.score(X_test_ln, y_test_ln)
score_lgbm_ln

# predict
y_pred_lgbm_ln = (reg_ln).fit(X_train_ln, y_train_ln).predict(ml_test_ln)
y_pred_lgbm_ln

# submit
submission["중식계"] = y_pred_lgbm_ln
submission["중식계"][:5]



# valid score
score_lgbm_dn = reg_dn.score(X_test_dn, y_test_dn)
score_lgbm_dn

# predict
y_pred_lgbm_dn = (reg_dn).fit(X_train_dn, y_train_dn).predict(ml_test_dn)
y_pred_lgbm_dn

# submit
submission["석식계"] = y_pred_lgbm_dn
submission["석식계"][:5]



# 캐글에 제출
file_name = f'7_전체_{score_lgbm_ln}.csv'
submission.to_csv(file_name, index = False)
pd.read_csv(file_name).head()

submission.head(2)





